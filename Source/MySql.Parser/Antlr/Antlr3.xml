<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Antlr3</name>
    </assembly>
    <members>
        <member name="T:Antlr3.Analysis.AnalysisRecursionOverflowException">
            An NFA configuration context stack overflowed. 
        </member>
        <member name="T:Antlr3.Analysis.AnalysisTimeoutException">
            Analysis took too long; bail out of entire DFA construction. 
        </member>
        <member name="T:Antlr3.Analysis.DecisionProbe">
            Collection of information about what is wrong with a decision as
              discovered while building the DFA predictor.
            
              The information is collected during NFA->DFA conversion and, while
              some of this is available elsewhere, it is nice to have it all tracked
              in one spot so a great error message can be easily had.  I also like
              the fact that this object tracks it all for later perusing to make an
              excellent error message instead of lots of imprecise on-the-fly warnings
              (during conversion).
            
              A decision normally only has one problem; e.g., some input sequence
              can be matched by multiple alternatives.  Unfortunately, some decisions
              such as
            
              a : ( A | B ) | ( A | B ) | A ;
            
              have multiple problems.  So in general, you should approach a decision
              as having multiple flaws each one uniquely identified by a DFAState.
              For example, statesWithSyntacticallyAmbiguousAltsSet tracks the set of
              all DFAStates where ANTLR has discovered a problem.  Recall that a decision
              is represented internall with a DFA comprised of multiple states, each of
              which could potentially have problems.
            
              Because of this, you need to iterate over this list of DFA states.  You'll
              note that most of the informational methods like
              getSampleNonDeterministicInputSequence() require a DFAState.  This state
              will be one of the iterated states from stateToSyntacticallyAmbiguousAltsSet.
            
              This class is not thread safe due to shared use of visited maps etc...
              Only one thread should really need to access one DecisionProbe anyway.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._statesWithSyntacticallyAmbiguousAltsSet">
            Track all DFA states with nondeterministic alternatives.
            By reaching the same DFA state, a path through the NFA for some input
            is able to reach the same NFA state by starting at more than one
            alternative's left edge.  Though, later, we may find that predicates
            resolve the issue, but track info anyway.
            Note that from the DFA state, you can ask for
            which alts are nondeterministic.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe.stateToSyntacticallyAmbiguousTokensRuleAltsMap">
            Track just like stateToSyntacticallyAmbiguousAltsMap, but only
            for nondeterminisms that arise in the Tokens rule such as keyword vs
            ID rule.  The state maps to the list of Tokens rule alts that are
            in conflict.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._statesResolvedWithSemanticPredicatesSet">
            Was a syntactic ambiguity resolved with predicates?  Any DFA
            state that predicts more than one alternative, must be resolved
            with predicates or it should be reported to the user.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._stateToAltSetWithSemanticPredicatesMap">
            Track the predicates for each alt per DFA state;
            more than one DFA state might have syntactically ambig alt prediction.
            Maps DFA state to another map, mapping alt number to a
            SemanticContext (pred(s) to execute to resolve syntactic ambiguity).
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._stateToIncompletelyCoveredAltsMap">
            Tracks alts insufficiently covered.
            For example, p1||true gets reduced to true and so leaves
            whole alt uncovered.  This maps DFA state to the set of alts
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._danglingStates">
            The set of states w/o emanating edges and w/o resolving sem preds. 
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._altsWithProblem">
            The overall list of alts within the decision that have at least one
            conflicting input sequence.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._nonLLStarDecision">
            If decision with > 1 alt has recursion in > 1 alt, it's (likely) nonregular
            lookahead.  The decision cannot be made with a DFA.
            the alts are stored in altsWithProblem.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._stateToRecursionOverflowConfigurationsMap">
            Recursion is limited to a particular depth.  If that limit is exceeded
            the proposed new NFAConfiguration is recorded for the associated DFA state.
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._stateReachable">
            Used to find paths through syntactically ambiguous DFA. If we've
            seen statement number before, what did we learn?
        </member>
        <member name="F:Antlr3.Analysis.DecisionProbe._statesVisitedAtInputDepth">
            Used while finding a path through an NFA whose edge labels match
            an input sequence.  Tracks the input position
            we were at the last time at this node.  If same input position, then
            we'd have reached same state without consuming input...probably an
            infinite loop.  Stop.  Set of strings.  The strings look like
            stateNumber_labelIndex.
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.AnalysisOverflowed">
            Took too long to analyze a DFA 
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.DanglingStates">
            return set of states w/o emanating edges and w/o resolving sem preds.
            These states come about because the analysis algorithm had to
            terminate early to avoid infinite recursion for example (due to
            left recursion perhaps).
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.Description">
            Return a string like "3:22: ( A {;} | B )" that describes this
            decision.
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.DFAStatesWithSyntacticallyAmbiguousAlts">
            Return all DFA states in this DFA that have NFA configurations that
            conflict.  You must report a problem for each state in this set
            because each state represents a different input sequence.
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.HasPredicate">
            At least one alt refs a sem or syn pred 
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.IsDeterministic">
            If no states are dead-ends, no alts are unreachable, there are
            no nondeterminisms unresolved by syn preds, all is ok with decision.
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.IsNonLLStarDecision">
            Found recursion in > 1 alt 
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.NumberOfStates">
            How many states does the DFA predictor have? 
        </member>
        <member name="P:Antlr3.Analysis.DecisionProbe.UnreachableAlts">
            Get a list of all unreachable alternatives for this decision.  There
            may be multiple alternatives with ambiguous input sequences, but this
            is the overall list of unreachable alternatives (either due to
            conflict resolution or alts w/o accept states).
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetNonDeterministicAltsForState(Antlr3.Analysis.DFAState)">
            Return the sorted list of alts that conflict within a single state.
            Note that predicates may resolve the conflict.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetDisabledAlternatives(Antlr3.Analysis.DFAState)">
            Which alts were specifically turned off to resolve nondeterminisms?
            This is different than the unreachable alts.  Disabled doesn't mean that
            the alternative is totally unreachable necessarily, it just means
            that for this DFA state, that alt is disabled.  There may be other
            accept states for that alt that make an alt reachable.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.RemoveRecursiveOverflowState(Antlr3.Analysis.DFAState)">
            If a recursion overflow is resolve with predicates, then we need
            to shut off the warning that would be generated.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetSampleNonDeterministicInputSequence(Antlr3.Analysis.DFAState)">
            Return a IList&lt;Label&gt; indicating an input sequence that can be matched
            from the start state of the DFA to the targetState (which is known
            to have a problem).
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetInputSequenceDisplay(System.Collections.Generic.IList{Antlr3.Analysis.Label})">
            Given IList&lt;Label&gt;, return a String with a useful representation
            of the associated input string.  One could show something different
            for lexers and parsers, for example.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetNFAPathStatesForAlt(System.Int32,System.Int32,System.Collections.Generic.IList{Antlr3.Analysis.Label})">
            Given an alternative associated with a nondeterministic DFA state,
              find the path of NFA states associated with the labels sequence.
              Useful tracing where in the NFA, a single input sequence can be
              matched.  For different alts, you should get different NFA paths.
            
              The first NFA state for all NFA paths will be the same: the starting
              NFA state of the first nondeterministic alt.  Imagine (A|B|A|A):
            
             	5->9-A->o
              |
              6->10-B->o
              |
              7->11-A->o
              |
              8->12-A->o
            
              There are 3 nondeterministic alts.  The paths should be:
              5 9 ...
              5 6 7 11 ...
              5 6 7 8 12 ...
            
              The NFA path matching the sample input sequence (labels) is computed
              using states 9, 11, and 12 rather than 5, 7, 8 because state 5, for
              example can get to all ambig paths.  Must isolate for each alt (hence,
              the extra state beginning each alt in my NFA structures).  Here,
              firstAlt=1.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetSemanticContextForAlt(Antlr3.Analysis.DFAState,System.Int32)">
            Each state in the DFA represents a different input sequence for an
            alt of the decision.  Given a DFA state, what is the semantic
            predicate context for a particular alt.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetIncompletelyCoveredAlts(Antlr3.Analysis.DFAState)">
            Return a list of alts whose predicate context was insufficient to
            resolve a nondeterminism for state d.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.StripWildCardAlts(System.Collections.Generic.ICollection{System.Int32})">
            Get the last disabled alt number and check in the grammar to see
            if that alt is a simple wildcard.  If so, treat like an else clause
            and don't emit the error.  Strip out the last alt if it's wildcard.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.ReportDanglingState(Antlr3.Analysis.DFAState)">
            Report the fact that DFA state d is not a state resolved with
            predicates and yet it has no emanating edges.  Usually this
            is a result of the closure/reach operations being unable to proceed
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.ReportNonLLStarDecision(Antlr3.Analysis.DFA)">
            Report that at least 2 alts have recursive constructs.  There is
            no way to build a DFA so we terminated.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.ReportLexerRuleNondeterminism(Antlr3.Analysis.DFAState,System.Collections.Generic.HashSet{System.Int32})">
            Currently the analysis reports issues between token definitions, but
            we don't print out warnings in favor of just picking the first token
            definition found in the grammar ala lex/flex.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.ReportAltPredicateContext(Antlr3.Analysis.DFAState,System.Collections.Generic.IDictionary{System.Int32,Antlr3.Analysis.SemanticContext})">
            Report the list of predicates found for each alternative; copy
            the list because this set gets altered later by the method
            tryToResolveWithSemanticPredicates() while flagging NFA configurations
            in d as resolved.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.ReachesState(Antlr3.Analysis.DFAState,Antlr3.Analysis.DFAState,System.Collections.Generic.HashSet{System.Object})">
            Given a start state and a target state, return true if start can reach
            target state.  Also, compute the set of DFA states
            that are on a path from start to target; return in states parameter.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetSampleInputSequenceUsingStateSet(Antlr3.Analysis.State,Antlr3.Analysis.State,System.Collections.Generic.HashSet{System.Object},System.Collections.Generic.IList{Antlr3.Analysis.Label})">
            Given a start state and a final state, find a list of edge labels
            between the two ignoring epsilon.  Limit your scan to a set of states
            passed in.  This is used to show a sample input sequence that is
            nondeterministic with respect to this decision.  Return IList&lt;Label&gt; as
            a parameter.  The incoming states set must be all states that lead
            from startState to targetState and no others so this algorithm doesn't
            take a path that eventually leads to a state other than targetState.
            Don't follow loops, leading to short (possibly shortest) path.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetNFAPath(Antlr3.Analysis.NFAState,System.Int32,System.Collections.Generic.IList{Antlr3.Analysis.Label},System.Collections.Generic.IList{Antlr3.Analysis.NFAState})">
            Given a sample input sequence, you usually would like to know the
            path taken through the NFA.  Return the list of NFA states visited
            while matching a list of labels.  This cannot use the usual
            interpreter, which does a deterministic walk.  We need to be able to
            take paths that are turned off during nondeterminism resolution. So,
            just do a depth-first walk traversing edges labeled with the current
            label.  Return true if a path was found emanating from state s.
        </member>
        <member name="M:Antlr3.Analysis.DecisionProbe.GetTokenNameForTokensRuleAlt(System.Int32)">
            From an alt number associated with artificial Tokens rule, return
            the name of the token that is associated with that alt.
        </member>
        <member name="T:Antlr3.Analysis.DFA">
            A DFA (converted from a grammar's NFA).
            DFAs are used as prediction machine for alternative blocks in all kinds
            of recognizers (lexers, parsers, tree walkers).
        </member>
        <member name="F:Antlr3.Analysis.DFA.MAX_TIME_PER_DFA_CREATION">
            Set to 0 to not terminate early (time in ms) 
        </member>
        <member name="F:Antlr3.Analysis.DFA.MAX_STATE_TRANSITIONS_FOR_TABLE">
            How many edges can each DFA state have before a "special" state
            is created that uses IF expressions instead of a table?
        </member>
        <member name="F:Antlr3.Analysis.DFA._startState">
            What's the start state for this DFA? 
        </member>
        <member name="F:Antlr3.Analysis.DFA._decisionNumber">
            This DFA is being built for which decision? 
        </member>
        <member name="F:Antlr3.Analysis.DFA._decisionNFAStartState">
            From what NFAState did we create the DFA? 
        </member>
        <member name="F:Antlr3.Analysis.DFA._description">
            The printable grammar fragment associated with this DFA 
        </member>
        <member name="F:Antlr3.Analysis.DFA._uniqueStates">
            A set of all uniquely-numbered DFA states.  Maps hash of DFAState
            to the actual DFAState object.  We use this to detect
            existing DFA states.  Map&lt;DFAState,DFAState&gt;.  Use Map so
            we can get old state back (Set only allows you to see if it's there).
            Not used during fixed k lookahead as it's a waste to fill it with
            a dup of states array.
        </member>
        <member name="F:Antlr3.Analysis.DFA._states">
            Maps the state number to the actual DFAState.  Use a Vector as it
              grows automatically when I set the ith element.  This contains all
              states, but the states are not unique.  s3 might be same as s1 so
              s3 -> s1 in this table.  This is how cycles occur.  If fixed k,
              then these states will all be unique as states[i] always points
              at state i when no cycles exist.
            
              This is managed in parallel with uniqueStates and simply provides
              a way to go from state number to DFAState rather than via a
              hash lookup.
        </member>
        <member name="F:Antlr3.Analysis.DFA._stateCounter">
            Unique state numbers per DFA 
        </member>
        <member name="F:Antlr3.Analysis.DFA._numberOfStates">
            count only new states not states that were rejected as already present 
        </member>
        <member name="F:Antlr3.Analysis.DFA._userK">
            User specified max fixed lookahead.  If 0, nothing specified.  -1
            implies we have not looked at the options table yet to set k.
        </member>
        <member name="F:Antlr3.Analysis.DFA._max_k">
            <summary>
            While building the DFA, track max lookahead depth if not cyclic.
            </summary>
        </member>
        <member name="F:Antlr3.Analysis.DFA._reduced">
            Is this DFA reduced?  I.e., can all states lead to an accept state? 
        </member>
        <member name="F:Antlr3.Analysis.DFA._cyclic">
            Are there any loops in this DFA?
            Computed by doesStateReachAcceptState()
        </member>
        <member name="F:Antlr3.Analysis.DFA._predicateVisible">
            Track whether this DFA has at least one sem/syn pred encountered
            during a closure operation.  This is useful for deciding whether
            to retry a non-LL(*) with k=1.  If no pred, it will not work w/o
            a pred so don't bother.  It would just give another error message.
        </member>
        <member name="F:Antlr3.Analysis.DFA._unreachableAlts">
            Each alt in an NFA derived from a grammar must have a DFA state that
            predicts it lest the parser not know what to do.  Nondeterminisms can
            lead to this situation (assuming no semantic predicates can resolve
            the problem) and when for some reason, I cannot compute the lookahead
            (which might arise from an error in the algorithm or from
            left-recursion etc...).  This list starts out with all alts contained
            and then in method doesStateReachAcceptState() I remove the alts I
            know to be uniquely predicted.
        </member>
        <member name="F:Antlr3.Analysis.DFA._altToAcceptState">
            We only want one accept state per predicted alt; track here 
        </member>
        <member name="F:Antlr3.Analysis.DFA._recursiveAltSet">
            Track whether an alt discovers recursion for each alt during
            NFA to DFA conversion; >1 alt with recursion implies nonregular.
        </member>
        <member name="F:Antlr3.Analysis.DFA._nfa">
            Which NFA are we converting (well, which piece of the NFA)? 
        </member>
        <member name="F:Antlr3.Analysis.DFA._probe">
            This probe tells you a lot about a decision and is useful even
            when there is no error such as when a syntactic nondeterminism
            is solved via semantic predicates.  Perhaps a GUI would want
            the ability to show that.
        </member>
        <member name="F:Antlr3.Analysis.DFA._edgeTransitionClassMap">
            Map an edge transition table to a unique set number; ordered so
            we can push into the output template as an ordered list of sets
            and then ref them from within the transition[][] table.  Like this
            for C# target:
               public static readonly DFA30_transition0 =
               	new short[] { 46, 46, -1, 46, 46, -1, -1, -1, -1, -1, -1, -1,...};
                   public static readonly DFA30_transition1 =
               	new short[] { 21 };
                public static readonly short[][] DFA30_transition = {
               	  DFA30_transition0,
               	  DFA30_transition0,
               	  DFA30_transition1,
               	  ...
                };
        </member>
        <member name="F:Antlr3.Analysis.DFA._edgeTransitionClass">
            The unique edge transition class number; every time we see a new
            set of edges emanating from a state, we number it so we can reuse
            if it's every seen again for another state.  For Java grammar,
            some of the big edge transition tables are seen about 57 times.
        </member>
        <member name="F:Antlr3.Analysis.DFA._specialStates">
            List of special DFAState objects 
        </member>
        <member name="F:Antlr3.Analysis.DFA._specialStateSTs">
            List of ST for special states. 
        </member>
        <member name="F:Antlr3.Analysis.DFA._transitionEdgeTables">
            just the Vector&lt;Integer&gt; indicating which unique edge table is at
            position i.
        </member>
        <member name="F:Antlr3.Analysis.DFA._generator">
            Which generator to use if we're building state tables 
        </member>
        <member name="P:Antlr3.Analysis.DFA.DecisionASTNode">
            What GrammarAST node (derived from the grammar) is this DFA
            associated with?  It will point to the start of a block or
            the loop back of a (...)+ block etc...
        </member>
        <member name="P:Antlr3.Analysis.DFA.IsCyclic">
            Is this DFA cyclic?  That is, are there any loops?  If not, then
            the DFA is essentially an LL(k) predictor for some fixed, max k value.
            We can build a series of nested IF statements to match this.  In the
            presence of cycles, we need to build a general DFA and interpret it
            to distinguish between alternatives.
        </member>
        <member name="P:Antlr3.Analysis.DFA.MaxLookahead">
            <summary>
            While building the DFA, track max lookahead depth if not cyclic.
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.DFA.IsReduced">
            Is the DFA reduced?  I.e., does every state have a path to an accept
            state?  If not, don't delete as we need to generate an error indicating
            which paths are "dead ends".  Also tracks list of alts with no accept
            state in the DFA.  Must call verify() first before this makes sense.
        </member>
        <member name="P:Antlr3.Analysis.DFA.MaxLookaheadDepth">
            Return k if decision is LL(k) for some k else return max int
        </member>
        <member name="P:Antlr3.Analysis.DFA.MaxStateNumber">
            What is the max state number ever created?  This may be beyond
            getNumberOfStates().
        </member>
        <member name="P:Antlr3.Analysis.DFA.UnreachableAlts">
            Return a list of Integer alt numbers for which no lookahead could
            be computed or for which no single DFA accept state predicts those
            alts.  Must call verify() first before this makes sense.
        </member>
        <member name="P:Antlr3.Analysis.DFA.HasSynPred">
            Count all disambiguating syn preds (ignore synpred tests
              for gated edges, which occur for nonambig input sequences).
              E.g.,
              x  : (X)=> (X|Y)\n" +
                 | X\n" +
                 ;
            
              gives
             
             .s0-X->.s1
             .s0-Y&amp;&amp;{synpred1_t}?->:s2=>1
             .s1-{synpred1_t}?->:s2=>1
             .s1-{true}?->:s3=>2
        </member>
        <member name="P:Antlr3.Analysis.DFA.HasCycle">
            Compute cyclic w/o relying on state computed during analysis. just check. 
        </member>
        <member name="M:Antlr3.Analysis.DFA.ResetStateNumbersToBeContiguous">
            Walk all states and reset their numbers to be a contiguous sequence
              of integers starting from 0.  Only cyclic DFA can have unused positions
              in states list.  State i might be identical to a previous state j and
              will result in states[i] == states[j].  We don't want to waste a state
              number on this.  Useful mostly for code generation in tables.
            
              At the start of this routine, states[i].stateNumber &lt;= i by definition.
              If states[50].stateNumber is 50 then a cycle during conversion may
              try to add state 103, but we find that an identical DFA state, named
              50, already exists, hence, states[103]==states[50] and both have
              stateNumber 50 as they point at same object.  Afterwards, the set
              of state numbers from all states should represent a contiguous range
              from 0..n-1 where n is the number of unique states.
        </member>
        <member name="M:Antlr3.Analysis.DFA.GetRunLengthEncoding(System.Int32[])">
            Compress the incoming data list so that runs of same number are
              encoded as number,value pair sequences.  3 -1 -1 -1 28 is encoded
              as 1 3 3 -1 1 28.  I am pretty sure this is the lossless compression
              that GIF files use.  Transition tables are heavily compressed by
              this technique.  I got the idea from JFlex http://jflex.de/
            
              Return List&lt;String&gt; where each string is either \xyz for 8bit char
              and \uFFFF for 16bit.  Hideous and specific to Java, but it is the
              only target bad enough to need it.
        </member>
        <member name="M:Antlr3.Analysis.DFA.CreateEOTAndEOFTables(Antlr3.Analysis.DFAState)">
            Set up the EOT and EOF tables; we cannot put -1 min/max values so
            we need another way to test that in the DFA transition function.
        </member>
        <member name="M:Antlr3.Analysis.DFA.AddState(Antlr3.Analysis.DFAState)">
            Add a new DFA state to this DFA if not already present.
            To force an acyclic, fixed maximum depth DFA, just always
            return the incoming state.  By not reusing old states,
            no cycles can be created.  If we're doing fixed k lookahead
            don't updated uniqueStates, just return incoming state, which
            indicates it's a new state.
        </member>
        <member name="M:Antlr3.Analysis.DFA.GetIsTokensRuleDecision">
            Is this DFA derived from the NFA for the Tokens rule? 
        </member>
        <member name="M:Antlr3.Analysis.DFA.GetUserMaxLookahead">
            The user may specify a max, acyclic lookahead for any decision.  No
            DFA cycles are created when this value, k, is greater than 0.
            If this decision has no k lookahead specified, then try the grammar.
        </member>
        <member name="M:Antlr3.Analysis.DFA.Verify">
            Once this DFA has been built, need to verify that:
            
              1. it's reduced
              2. all alts have an accept state
            
              Elsewhere, in the NFA converter, we need to verify that:
            
              3. alts i and j have disjoint lookahead if no sem preds
              4. if sem preds, nondeterministic alts must be sufficiently covered
            
              This is avoided if analysis bails out for any reason.
        </member>
        <member name="M:Antlr3.Analysis.DFA.DoesStateReachAcceptState(Antlr3.Analysis.DFAState)">
            figure out if this state eventually reaches an accept state and
              modify the instance variable 'reduced' to indicate if we find
              at least one state that cannot reach an accept state.  This implies
              that the overall DFA is not reduced.  This algorithm should be
              linear in the number of DFA states.
            
              The algorithm also tracks which alternatives have no accept state,
              indicating a nondeterminism.
            
              Also computes whether the DFA is cyclic.
            
              TODO: I call getUniquelyPredicatedAlt too much; cache predicted alt
        </member>
        <member name="M:Antlr3.Analysis.DFA.FindAllGatedSynPredsUsedInDFAAcceptStates">
            Walk all accept states and find the manually-specified synpreds.
            Gated preds are not always hoisted
            I used to do this in the code generator, but that is too late.
            This converter tries to avoid computing DFA for decisions in
            syntactic predicates that are not ever used such as those
            created by autobacktrack mode.
        </member>
        <member name="M:Antlr3.Analysis.DFA.OkToRetryDFAWithK1">
            If this DFA failed to finish during construction, we might be
            able to retry with k=1 but we need to know whether it will
            potentially succeed.  Can only succeed if there is a predicate
            to resolve the issue.  Don't try if k=1 already as it would
            cycle forever.  Timeout can retry with k=1 even if no predicate
            if k!=1.
        </member>
        <member name="T:Antlr3.Analysis.DFAOptimizer">
            A module to perform optimizations on DFAs.
            
              I could more easily (and more quickly) do some optimizations (such as
              PRUNE_EBNF_EXIT_BRANCHES) during DFA construction, but then it
              messes up the determinism checking.  For example, it looks like
              loop exit branches are unreachable if you prune exit branches
              during DFA construction and before determinism checks.
            
              In general, ANTLR's NFA->DFA->codegen pipeline seems very robust
              to me which I attribute to a uniform and consistent set of data
              structures.  Regardless of what I want to "say"/implement, I do so
              within the confines of, for example, a DFA.  The code generator
              can then just generate code--it doesn't have to do much thinking.
              Putting optimizations in the code gen code really starts to make
              it a spagetti factory (uh oh, now I'm hungry!).  The pipeline is
              very testable; each stage has well defined input/output pairs.
            
              ### Optimization: PRUNE_EBNF_EXIT_BRANCHES
            
              There is no need to test EBNF block exit branches.  Not only is it
              an unneeded computation, but counter-intuitively, you actually get
              better errors. You can report an error at the missing or extra
              token rather than as soon as you've figured out you will fail.
            
              Imagine optional block "( DOT CLASS )? SEMI".  ANTLR generates:
            
              int alt=0;
              if ( input.LA(1)==DOT ) {
                  alt=1;
              }
              else if ( input.LA(1)==SEMI ) {
                  alt=2;
              }
            
              Clearly, since Parser.match() will ultimately find the error, we
              do not want to report an error nor do we want to bother testing
              lookahead against what follows the (...)?  We want to generate
              simply "should I enter the subrule?":
            
              int alt=2;
              if ( input.LA(1)==DOT ) {
                  alt=1;
              }
            
              NOTE 1. Greedy loops cannot be optimized in this way.  For example,
              "(greedy=false:'x'|.)* '\n'".  You specifically need the exit branch
              to tell you when to terminate the loop as the same input actually
              predicts one of the alts (i.e., staying in the loop).
            
              NOTE 2.  I do not optimize cyclic DFAs at the moment as it doesn't
              seem to work. ;)  I'll have to investigate later to see what work I
              can do on cyclic DFAs to make them have fewer edges.  Might have
              something to do with the EOT token.
            
              ### PRUNE_SUPERFLUOUS_EOT_EDGES
            
              When a token is a subset of another such as the following rules, ANTLR
              quietly assumes the first token to resolve the ambiguity.
            
              EQ			: '=' ;
              ASSIGNOP	: '=' | '+=' ;
            
              It can yield states that have only a single edge on EOT to an accept
              state.  This is a waste and messes up my code generation. ;)  If
              Tokens rule DFA goes
            
             		s0 -'='-> s3 -EOT-> s5 (accept)
            
              then s5 should be pruned and s3 should be made an accept.  Do NOT do this
              for keyword versus ID as the state with EOT edge emanating from it will
              also have another edge.
            
              ### Optimization: COLLAPSE_ALL_INCIDENT_EDGES
            
              Done during DFA construction.  See method addTransition() in
              NFAToDFAConverter.
            
              ### Optimization: MERGE_STOP_STATES
            
              Done during DFA construction.  See addDFAState() in NFAToDFAConverter.
        </member>
        <member name="F:Antlr3.Analysis.DFAOptimizer._visited">
            Used by DFA state machine generator to avoid infinite recursion
            resulting from cycles int the DFA.  This is a set of int state #s.
            This is a side-effect of calling optimize; can't clear after use
            because code gen needs it.
        </member>
        <member name="T:Antlr3.Analysis.DFAState">
            A DFA state represents a set of possible NFA configurations.
              As Aho, Sethi, Ullman p. 117 says "The DFA uses its state
              to keep track of all possible states the NFA can be in after
              reading each input symbol.  That is to say, after reading
              input a1a2..an, the DFA is in a state that represents the
              subset T of the states of the NFA that are reachable from the
              NFA's start state along some path labeled a1a2..an."
              In conventional NFA->DFA conversion, therefore, the subset T
              would be a bitset representing the set of states the
              NFA could be in.  We need to track the alt predicted by each
              state as well, however.  More importantly, we need to maintain
              a stack of states, tracking the closure operations as they
              jump from rule to rule, emulating rule invocations (method calls).
              Recall that NFAs do not normally have a stack like a pushdown-machine
              so I have to add one to simulate the proper lookahead sequences for
              the underlying LL grammar from which the NFA was derived.
            
              I use a list of NFAConfiguration objects.  An NFAConfiguration
              is both a state (ala normal conversion) and an NFAContext describing
              the chain of rules (if any) followed to arrive at that state.  There
              is also the semantic context, which is the "set" of predicates found
              on the path to this configuration.
            
              A DFA state may have multiple references to a particular state,
              but with different NFAContexts (with same or different alts)
              meaning that state was reached via a different set of rule invocations.
        </member>
        <member name="F:Antlr3.Analysis.DFAState.dfa">
            We are part of what DFA?  Use this ref to get access to the
            context trees for an alt.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._transitions">
            Track the transitions emanating from this DFA state.  The List
            elements are Transition objects.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._k">
            When doing an acyclic DFA, this is the number of lookahead symbols
            consumed to reach this state.  This value may be nonzero for most
            dfa states, but it is only a valid value if the user has specified
            a max fixed lookahead.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._acceptStateReachable">
            The NFA->DFA algorithm may terminate leaving some states
            without a path to an accept state, implying that upon certain
            input, the decision is not deterministic--no decision about
            predicting a unique alternative can be made.  Recall that an
            accept state is one in which a unique alternative is predicted.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._resolvedWithPredicates">
            Rather than recheck every NFA configuration in a DFA state (after
            resolving) in findNewDFAStatesAndAddDFATransitions just check
            this boolean.  Saves a linear walk perhaps DFA state creation.
            Every little bit helps.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._abortedDueToRecursionOverflow">
            If a closure operation finds that we tried to invoke the same
            rule too many times (stack would grow beyond a threshold), it
            marks the state has aborted and notifies the DecisionProbe.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._abortedDueToMultipleRecursiveAlts">
            If we detect recursion on more than one alt, decision is non-LL(*),
              but try to isolate it to only those states whose closure operations
              detect recursion.  There may be other alts that are cool:
            
              a : recur '.'
                | recur ';'
                | X Y  // LL(2) decision; don't abort and use k=1 plus backtracking
                | X Z
                ;
            
              12/13/2007: Actually this has caused problems.  If k=*, must terminate
              and throw out entire DFA; retry with k=1.  Since recursive, do not
              attempt more closure ops as it may take forever.  Exception thrown
              now and we simply report the problem.  If synpreds exist, I'll retry
              with k=1.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._cachedHashCode">
            Build up the hash code for this state as NFA configurations
            are added as it's monotonically increasing list of configurations.
        </member>
        <member name="F:Antlr3.Analysis.DFAState._nfaConfigurations">
            The set of NFA configurations (state,alt,context) for this DFA state 
        </member>
        <member name="F:Antlr3.Analysis.DFAState._closureBusy">
            Used to prevent the closure operation from looping to itself and
              hence looping forever.  Sensitive to the NFA state, the alt, and
              the stack context.  This just the nfa config set because we want to
              prevent closures only on states contributed by closure not reach
              operations.
            
              Two configurations identical including semantic context are
              considered the same closure computation.  @see NFAToDFAConverter.closureBusy().
        </member>
        <member name="F:Antlr3.Analysis.DFAState._reachableLabels">
            As this state is constructed (i.e., as NFA states are added), we
            can easily check for non-epsilon transitions because the only
            transition that could be a valid label is transition(0).  When we
            process this node eventually, we'll have to walk all states looking
            for all possible transitions.  That is of the order: size(label space)
            times size(nfa states), which can be pretty damn big.  It's better
            to simply track possible labels.
        </member>
        <member name="P:Antlr3.Analysis.DFAState.AcceptStateReachable">
            Is an accept state reachable from this state? 
        </member>
        <member name="P:Antlr3.Analysis.DFAState.AltSet">
            Get the set of all alts mentioned by all NFA configurations in this
            DFA state.
        </member>
        <member name="P:Antlr3.Analysis.DFAState.DisabledAlternatives">
            When more than one alternative can match the same input, the first
              alternative is chosen to resolve the conflict.  The other alts
              are "turned off" by setting the "resolved" flag in the NFA
              configurations.  Return the set of disabled alternatives.  For
            
              a : A | A | A ;
            
              this method returns {2,3} as disabled.  This does not mean that
              the alternative is totally unreachable, it just means that for this
              DFA state, that alt is disabled.  There may be other accept states
              for that alt.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.AddTransition(Antlr3.Analysis.DFAState,Antlr3.Analysis.Label)">
            Add a transition from this state to target with label.  Return
            the transition number from 0..n-1.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.AddNFAConfiguration(Antlr3.Analysis.NFAState,Antlr3.Analysis.NFAConfiguration)">
            Add an NFA configuration to this DFA node.  Add uniquely
              an NFA state/alt/syntactic&amp;semantic context (chain of invoking state(s)
              and semantic predicate contexts).
            
              I don't see how there could be two configurations with same
              state|alt|synCtx and different semantic contexts because the
              semantic contexts are computed along the path to a particular state
              so those two configurations would have to have the same predicate.
              Nonetheless, the addition of configurations is unique on all
              configuration info.  I guess I'm saying that syntactic context
              implies semantic context as the latter is computed according to the
              former.
            
              As we add configurations to this DFA state, track the set of all possible
              transition labels so we can simply walk it later rather than doing a
              loop over all possible labels in the NFA.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.AddReachableLabel(Antlr3.Analysis.Label)">
            Add label uniquely and disjointly; intersection with
              another set or int/char forces breaking up the set(s).
            
              Example, if reachable list of labels is [a..z, {k,9}, 0..9],
              the disjoint list will be [{a..j,l..z}, k, 9, 0..8].
            
              As we add NFA configurations to a DFA state, we might as well track
              the set of all possible transition labels to make the DFA conversion
              more efficient.  W/o the reachable labels, we'd need to check the
              whole vocabulary space (could be 0..\uFFFF)!  The problem is that
              labels can be sets, which may overlap with int labels or other sets.
              As we need a deterministic set of transitions from any
              state in the DFA, we must make the reachable labels set disjoint.
              This operation amounts to finding the character classes for this
              DFA state whereas with tools like flex, that need to generate a
              homogeneous DFA, must compute char classes across all states.
              We are going to generate DFAs with heterogeneous states so we
              only care that the set of transitions out of a single state are
              unique. :)
            
              The idea for adding a new set, t, is to look for overlap with the
              elements of existing list s.  Upon overlap, replace
              existing set s[i] with two new disjoint sets, s[i]-t and s[i]&amp;t.
              (if s[i]-t is nil, don't add).  The remainder is t-s[i], which is
              what you want to add to the set minus what was already there.  The
              remainder must then be compared against the i+1..n elements in s
              looking for another collision.  Each collision results in a smaller
              and smaller remainder.  Stop when you run out of s elements or
              remainder goes to nil.  If remainder is non nil when you run out of
              s elements, then add remainder to the end.
            
              Single element labels are treated as sets to make the code uniform.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.GetHashCode">
            A decent hash for a DFA state is the sum of the NFA state/alt pairs.
            This is used when we add DFAState objects to the DFA.states Map and
            when we compare DFA states.  Computed in addNFAConfiguration()
        </member>
        <member name="M:Antlr3.Analysis.DFAState.Equals(System.Object)">
            Two DFAStates are equal if their NFA configuration sets are the
              same. This method is used to see if a DFA state already exists.
            
              Because the number of alternatives and number of NFA configurations are
              finite, there is a finite number of DFA states that can be processed.
              This is necessary to show that the algorithm terminates.
            
              Cannot test the DFA state numbers here because in DFA.addState we need
              to know if any other state exists that has this exact set of NFA
              configurations.  The DFAState state number is irrelevant.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.GetUniquelyPredictedAlt">
            Walk each configuration and if they are all the same alt, return
            that alt else return NFA.INVALID_ALT_NUMBER.  Ignore resolved
            configurations, but don't ignore resolveWithPredicate configs
            because this state should not be an accept state.  We need to add
            this to the work list and then have semantic predicate edges
            emanating from it.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.GetUniqueAlt">
            Return the uniquely mentioned alt from the NFA configurations;
            Ignore the resolved bit etc...  Return INVALID_ALT_NUMBER
            if there is more than one alt mentioned.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.GetConflictingAlts">
            Walk each NFA configuration in this DFA state looking for a conflict
              where (s|i|ctx) and (s|j|ctx) exist, indicating that state s with
              context conflicting ctx predicts alts i and j.  Return an Integer set
              of the alternative numbers that conflict.  Two contexts conflict if
              they are equal or one is a stack suffix of the other or one is
              the empty context.
            
              Use a hash table to record the lists of configs for each state
              as they are encountered.  We need only consider states for which
              there is more than one configuration.  The configurations' predicted
              alt must be different or must have different contexts to avoid a
              conflict.
            
              Don't report conflicts for DFA states that have conflicting Tokens
              rule NFA states; they will be resolved in favor of the first rule.
        </member>
        <member name="M:Antlr3.Analysis.DFAState.GetGatedPredicatesInNFAConfigurations">
            For gated productions, we need an OR'd list of all predicates for the
              target of an edge so we can gate the edge based upon the predicates
              associated with taking that path (if any).
            
              For syntactic predicates, we only want to generate predicate
              evaluations as it transitions to an accept state; waste to
              do it earlier.  So, only add gated preds derived from manually-
              specified syntactic predicates if this is an accept state.
            
              Also, since configurations w/o gated predicates are like true
              gated predicates, finding a configuration whose alt has no gated
              predicate implies we should evaluate the predicate to true. This
              means the whole edge has to be ungated. Consider:
            
            	 X : ('a' | {p}?=> 'a')
            	   | 'a' 'b'
            	   ;
            
              Here, you 'a' gets you from s0 to s1 but you can't test p because
              plain 'a' is ok.  It's also ok for starting alt 2.  Hence, you can't
              test p.  Even on the edge going to accept state for alt 1 of X, you
              can't test p.  You can get to the same place with and w/o the context.
              Therefore, it is never ok to test p in this situation. 
            
              TODO: cache this as it's called a lot; or at least set bit if >1 present in state
        </member>
        <member name="M:Antlr3.Analysis.DFAState.ToString">
            Print all NFA states plus what alts they predict 
        </member>
        <member name="T:Antlr3.Analysis.Label">
            A state machine transition label.  A label can be either a simple
            label such as a token or character.  A label can be a set of char or
            tokens.  It can be an epsilon transition.  It can be a semantic predicate
            (which assumes an epsilon transition) or a tree of predicates (in a DFA).
            Special label types have to be &lt; 0 to avoid conflict with char.
        </member>
        <member name="F:Antlr3.Analysis.Label.SEMPRED">
            label is a semantic predicate; implies label is epsilon also 
        </member>
        <member name="F:Antlr3.Analysis.Label.SET">
            label is a set of tokens or char 
        </member>
        <member name="F:Antlr3.Analysis.Label.EOT">
            End of Token is like EOF for lexer rules.  It implies that no more
              characters are available and that NFA conversion should terminate
              for this path.  For example
            
              A : 'a' 'b' | 'a' ;
            
              yields a DFA predictor:
            
              o-a->o-b->1   predict alt 1
                   |
                   |-EOT->o predict alt 2
            
              To generate code for EOT, treat it as the "default" path, which
              implies there is no way to mismatch a char for the state from
              which the EOT emanates.
        </member>
        <member name="F:Antlr3.Analysis.Label.NUM_FAUX_LABELS">
            We have labels like EPSILON that are below 0; it's hard to
            store them in an array with negative index so use this
            constant as an index shift when accessing arrays based upon
            token type.  If real token type is i, then array index would be
            NUM_FAUX_LABELS + i.
        </member>
        <member name="F:Antlr3.Analysis.Label.MIN_ATOM_VALUE">
            Anything at this value or larger can be considered a simple atom int
            for easy comparison during analysis only; faux labels are not used
            during parse time for real token types or char values.
        </member>
        <member name="F:Antlr3.Analysis.Label.EOR_TOKEN_TYPE">
            End of rule token type; imaginary token type used only for
            local, partial FOLLOW sets to indicate that the local FOLLOW
            hit the end of rule.  During error recovery, the local FOLLOW
            of a token reference may go beyond the end of the rule and have
            to use FOLLOW(rule).  I have to just shift the token types to 2..n
            rather than 1..n to accommodate this imaginary token in my bitsets.
            If I didn't use a bitset implementation for runtime sets, I wouldn't
            need this.  EOF is another candidate for a run time token type for
            parsers.  Follow sets are not computed for lexers so we do not have
            this issue.
        </member>
        <member name="F:Antlr3.Analysis.Label.MIN_TOKEN_TYPE">
            tokens and char range overlap; tokens are MIN_TOKEN_TYPE..n 
        </member>
        <member name="F:Antlr3.Analysis.Label.label">
            The token type or character value; or, signifies special label. 
        </member>
        <member name="F:Antlr3.Analysis.Label._labelSet">
            A set of token types or character codes if label==SET 
        </member>
        <member name="M:Antlr3.Analysis.Label.#ctor(Antlr3.Misc.IIntSet)">
            Make a set label 
        </member>
        <member name="P:Antlr3.Analysis.Label.Atom">
            return the single atom label or INVALID if not a single atom 
        </member>
        <member name="P:Antlr3.Analysis.Label.IsAction">
            <summary>
            Gets whether or not the label is an action
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Label.IsAtom">
            <summary>
            Gets whether or not the label is an atom
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Label.IsEpsilon">
            <summary>
            Gets whether or not the label is an epsilon label
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Label.IsSemanticPredicate">
            <summary>
            Gets whether or not the label is a semantic predicate
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Label.IsSet">
            <summary>
            Gets whether or not the label matches a set
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Label.SemanticContext">
            <summary>
            Gets the semantic context for the label
            </summary>
        </member>
        <member name="T:Antlr3.Analysis.LL1Analyzer">
            Created by IntelliJ IDEA.
            User: parrt
            Date: Dec 31, 2007
            Time: 1:31:16 PM
            To change this template use File | Settings | File Templates.
        </member>
        <member name="F:Antlr3.Analysis.LL1Analyzer.DETECT_PRED_EOR">
            0	if we hit end of rule and invoker should keep going (epsilon) 
        </member>
        <member name="F:Antlr3.Analysis.LL1Analyzer.DETECT_PRED_FOUND">
            1	if we found a nonautobacktracking pred 
        </member>
        <member name="F:Antlr3.Analysis.LL1Analyzer.DETECT_PRED_NOT_FOUND">
            2	if we didn't find such a pred 
        </member>
        <member name="F:Antlr3.Analysis.LL1Analyzer._lookBusy">
            Used during LOOK to detect computation cycles 
        </member>
        <member name="M:Antlr3.Analysis.LL1Analyzer.First(Antlr3.Analysis.NFAState)">
            From an NFA state, s, find the set of all labels reachable from s.
              Used to compute follow sets for error recovery.  Never computes
              a FOLLOW operation.  FIRST stops at end of rules, returning EOR, unless
              invoked from another rule.  I.e., routine properly handles
            
                 a : b A ;
            
              where b is nullable.
            
              We record with EOR_TOKEN_TYPE if we hit the end of a rule so we can
              know at runtime (when these sets are used) to start walking up the
              follow chain to compute the real, correct follow set (as opposed to
              the FOLLOW, which is a superset).
            
              This routine will only be used on parser and tree parser grammars.
        </member>
        <member name="M:Antlr3.Analysis.LL1Analyzer.DetectConfoundingPredicates(Antlr3.Analysis.NFAState)">
            Is there a non-syn-pred predicate visible from s that is not in
              the rule enclosing s?  This accounts for most predicate situations
              and lets ANTLR do a simple LL(1)+pred computation.
            
              TODO: what about gated vs regular preds?
        </member>
        <member name="M:Antlr3.Analysis.LL1Analyzer.GetPredicates(Antlr3.Analysis.NFAState)">
            Return predicate expression found via epsilon edges from s.  Do
            not look into other rules for now.  Do something simple.  Include
            backtracking synpreds.
        </member>
        <member name="T:Antlr3.Analysis.LL1DFA">
            A special DFA that is exactly LL(1) or LL(1) with backtracking mode
            predicates to resolve edge set collisions.
        </member>
        <member name="M:Antlr3.Analysis.LL1DFA.#ctor(System.Int32,Antlr3.Analysis.NFAState,Antlr3.Analysis.LookaheadSet[])">
            From list of lookahead sets (one per alt in decision), create
              an LL(1) DFA.  One edge per set.
            
              s0-{alt1}->:o=>1
              | \
              |  -{alt2}->:o=>2
              |
              ...
        </member>
        <member name="M:Antlr3.Analysis.LL1DFA.#ctor(System.Int32,Antlr3.Analysis.NFAState,Antlr3.Misc.MultiMap{Antlr3.Misc.IntervalSet,System.Int32})">
            From a set of edgeset->list-of-alts mappings, create a DFA
            that uses syn preds for all |list-of-alts|>1.
        </member>
        <member name="T:Antlr3.Analysis.LookaheadSet">
            An LL(1) lookahead set; contains a set of token types and a "hasEOF"
            condition when the set contains EOF.  Since EOF is -1 everywhere and -1
            cannot be stored in my BitSet, I set a condition here.  There may be other
            reasons in the future to abstract a LookaheadSet over a raw BitSet.
        </member>
        <member name="M:Antlr3.Analysis.MachineProbe.GetEdgeLabels(Antlr3.Analysis.DFAState)">
            Return a list of edge labels from start state to targetState. 
        </member>
        <member name="M:Antlr3.Analysis.MachineProbe.GetInputSequenceDisplay(Antlr3.Tool.Grammar,System.Collections.Generic.List{Antlr3.Misc.IIntSet})">
            Given List&lt;IntSet&gt;, return a String with a useful representation of the
            associated input string. One could show something different for lexers
            and parsers, for example.
        </member>
        <member name="M:Antlr3.Analysis.MachineProbe.GetGrammarLocationsForInputSequence(System.Collections.Generic.List{System.Collections.Generic.HashSet{Antlr3.Analysis.NFAState}},System.Collections.Generic.List{Antlr3.Misc.IIntSet})">
            Given an alternative associated with a DFA state, return the list of
            tokens (from grammar) associated with path through NFA following the
            labels sequence. The nfaStates gives the set of NFA states associated
            with alt that take us from start to stop. One of the NFA states in
            nfaStates[i] will have an edge intersecting with labels[i].
        </member>
        <member name="T:Antlr3.Analysis.NFA">
            An NFA (collection of NFAStates) constructed from a grammar.  This
            NFA is one big machine for entire grammar.  Decision points are recorded
            by the Grammar object so we can, for example, convert to DFA or simulate
            the NFA (interpret a decision).
        </member>
        <member name="F:Antlr3.Analysis.NFA._grammar">
            This NFA represents which grammar? 
        </member>
        <member name="F:Antlr3.Analysis.NFA._factory">
            Which factory created this NFA? 
        </member>
        <member name="T:Antlr3.Analysis.NFAConfiguration">
            An NFA state, predicted alt, and syntactic/semantic context.
            The syntactic context is a pointer into the rule invocation
            chain used to arrive at the state.  The semantic context is
            the unordered set semantic predicates encountered before reaching
            an NFA state.
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._state">
            The NFA state associated with this configuration 
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._alt">
            What alt is predicted by this configuration 
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._context">
            What is the stack of rule invocations that got us to state? 
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._semanticContext">
            The set of semantic predicates associated with this NFA
            configuration.  The predicates were found on the way to
            the associated NFA state in this syntactic context.
            Set of AST: track nodes in grammar containing the predicate
            for error messages and such (nice to know where the predicate
            came from in case of duplicates etc...).  By using a set,
            the equals() method will correctly show {pred1,pred2} as equals()
            to {pred2,pred1}.
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._resolved">
            Indicate that this configuration has been resolved and no further
            DFA processing should occur with it.  Essentially, this is used
            as an "ignore" bit so that upon a set of nondeterministic configurations
            such as (s|2) and (s|3), I can set (s|3) to resolved=true (and any
            other configuration associated with alt 3).
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._resolveWithPredicate">
            This bit is used to indicate a semantic predicate will be
            used to resolve the conflict.  Method
            DFA.findNewDFAStatesAndAddDFATransitions will add edges for
            the predicates after it performs the reach operation.  The
            nondeterminism resolver sets this when it finds a set of
            nondeterministic configurations (as it does for "resolved" field)
            that have enough predicates to resolve the conflit.
        </member>
        <member name="F:Antlr3.Analysis.NFAConfiguration._singleAtomTransitionEmanating">
            Indicates that the NFA state associated with this configuration
            has exactly one transition and it's an atom (not epsilon etc...).
        </member>
        <member name="M:Antlr3.Analysis.NFAConfiguration.Equals(System.Object)">
            An NFA configuration is equal to another if both have
            the same state, the predict the same alternative, and
            syntactic/semantic contexts are the same.  I don't think
            the state|alt|ctx could be the same and have two different
            semantic contexts, but might as well define equals to be
            everything.
        </member>
        <member name="T:Antlr3.Analysis.NFAContext">
            A tree node for tracking the call chains for NFAs that invoke
              other NFAs.  These trees only have to point upwards to their parents
              so we can walk back up the tree (i.e., pop stuff off the stack).  We
              never walk from stack down down through the children.
            
              Each alt predicted in a decision has its own context tree,
              representing all possible return nodes.  The initial stack has
              EOF ("$") in it.  So, for m alternative productions, the lookahead
              DFA will have m NFAContext trees.
            
              To "push" a new context, just do "new NFAContext(context-parent, state)"
              which will add itself to the parent.  The root is NFAContext(null, null).
            
              The complete context for an NFA configuration is the set of invoking states
              on the path from this node thru the parent pointers to the root.
        </member>
        <member name="F:Antlr3.Analysis.NFAContext.MAX_SAME_RULE_INVOCATIONS_PER_NFA_CONFIG_STACK">
            This is similar to Bermudez's m constant in his LAR(m) where
              you bound the stack so your states don't explode.  The main difference
              is that I bound only recursion on the stack, not the simple stack size.
              This looser constraint will let the conversion roam further to find
              lookahead to resolve a decision.
            
              Bermudez's m operates differently as it is his LR stack depth
              I'm pretty sure it therefore includes all stack symbols.  Here I
              restrict the size of an NFA configuration to be finite because a
              stack component may mention the same NFA invocation state at
              most m times.  Hence, the number of DFA states will not grow forever.
              With recursive rules like
            
                e : '(' e ')' | INT ;
            
              you could chase your tail forever if somebody said "s : e '.' | e ';' ;"
              This constant prevents new states from being created after a stack gets
              "too big".  Actually (12/14/2007) I realize that this example is
              trapped by the non-LL(*) detector for recursion in > 1 alt.  Here is
              an example that trips stack overflow:
            
            	  s : a Y | A A A A A X ; // force recursion past m=4
            	  a : A a | Q;
            
              If that were:
            
            	  s : a Y | A+ X ;
            
              it could loop forever.
            
              Imagine doing a depth-first search on the e DFA...as you chase an input
              sequence you can recurse to same rule such as e above.  You'd have a
              chain of ((((.  When you get do some point, you have to give up.  The
              states in the chain will have longer and longer NFA config stacks.
              Must limit size.
            
              max=0 implies you cannot ever jump to another rule during closure.
              max=1 implies you can make as many calls as you want--you just
                    can't ever visit a state that is on your rule invocation stack.
             		  I.e., you cannot ever recurse.
              max=2 implies you are able to recurse once (i.e., call a rule twice
              	  from the same place).
            
              This tracks recursion to a rule specific to an invocation site!
              It does not detect multiple calls to a rule from different rule
              invocation states.  We are guaranteed to terminate because the
              stack can only grow as big as the number of NFA states * max.
            
              I noticed that the Java grammar didn't work with max=1, but did with
              max=4.  Let's set to 4. Recursion is sometimes needed to resolve some
              fixed lookahead decisions.
        </member>
        <member name="F:Antlr3.Analysis.NFAContext._invokingState">
            The NFA state that invoked another rule's start state is recorded
            on the rule invocation context stack.
        </member>
        <member name="F:Antlr3.Analysis.NFAContext._cachedHashCode">
            Computing the hashCode is very expensive and closureBusy()
            uses it to track when it's seen a state|ctx before to avoid
            infinite loops.  As we add new contexts, record the hash code
            as this.invokingState + parent.cachedHashCode.  Avoids walking
            up the tree for every hashCode().  Note that this caching works
            because a context is a monotonically growing tree of context nodes
            and nothing on the stack is ever modified...ctx just grows
            or shrinks.
        </member>
        <member name="P:Antlr3.Analysis.NFAContext.IsEmpty">
            A context is empty if there is no parent; meaning nobody pushed
            anything on the call stack.
        </member>
        <member name="M:Antlr3.Analysis.NFAContext.Equals(System.Object)">
            Two contexts are equals() if both have
              same call stack; walk upwards to the root.
              Recall that the root sentinel node has no invokingStates and no parent.
              Note that you may be comparing contexts in different alt trees.
            
              The hashCode is now cheap as it's computed once upon each context
              push on the stack.  Use it to make equals() more efficient.
        </member>
        <member name="M:Antlr3.Analysis.NFAContext.ConflictsWith(Antlr3.Analysis.NFAContext)">
            Two contexts conflict() if they are equals() or one is a stack suffix
              of the other.  For example, contexts [21 12 $] and [21 9 $] do not
              conflict, but [21 $] and [21 12 $] do conflict.  Note that I should
              probably not show the $ in this case.  There is a dummy node for each
              stack that just means empty; $ is a marker that's all.
            
              This is used in relation to checking conflicts associated with a
              single NFA state's configurations within a single DFA state.
              If there are configurations s and t within a DFA state such that
              s.state=t.state &amp;&amp; s.alt != t.alt &amp;&amp; s.ctx conflicts t.ctx then
              the DFA state predicts more than a single alt--it's nondeterministic.
              Two contexts conflict if they are the same or if one is a suffix
              of the other.
            
              When comparing contexts, if one context has a stack and the other
              does not then they should be considered the same context.  The only
              way for an NFA state p to have an empty context and a nonempty context
              is the case when closure falls off end of rule without a call stack
              and re-enters the rule with a context.  This resolves the issue I
              discussed with Sriram Srinivasan Feb 28, 2005 about not terminating
              fast enough upon nondeterminism.
        </member>
        <member name="M:Antlr3.Analysis.NFAContext.Suffix(Antlr3.Analysis.NFAContext)">
            [$] suffix any context
              [21 $] suffix [21 12 $]
              [21 12 $] suffix [21 $]
              [21 18 $] suffix [21 18 12 9 $]
              [21 18 12 9 $] suffix [21 18 $]
              [21 12 $] not suffix [21 9 $]
            
              Example "[21 $] suffix [21 12 $]" means: rule r invoked current rule
              from state 21.  Rule s invoked rule r from state 12 which then invoked
              current rule also via state 21.  While the context prior to state 21
              is different, the fact that both contexts emanate from state 21 implies
              that they are now going to track perfectly together.  Once they
              converged on state 21, there is no way they can separate.  In other
              words, the prior stack state is not consulted when computing where to
              go in the closure operation.  ?$ and ??$ are considered the same stack.
              If ? is popped off then $ and ?$ remain; they are now an empty and
              nonempty context comparison.  So, if one stack is a suffix of
              another, then it will still degenerate to the simple empty stack
              comparison case.
        </member>
        <member name="M:Antlr3.Analysis.NFAContext.RecursionDepthEmanatingFromState(System.Int32)">
            Given an NFA state number, how many times has the NFA-to-DFA
              conversion pushed that state on the stack?  In other words,
              the NFA state must be a rule invocation state and this method
              tells you how many times you've been to this state.  If none,
              then you have not called the target rule from this state before
              (though another NFA state could have called that target rule).
              If n=1, then you've been to this state before during this
              DFA construction and are going to invoke that rule again.
            
              Note that many NFA states can invoke rule r, but we ignore recursion
              unless you hit the same rule invocation state again.
        </member>
        <member name="T:Antlr3.Analysis.NFAConversionThread">
            Convert all decisions i..j inclusive in a thread 
        </member>
        <member name="T:Antlr3.Analysis.NFAState">
            A state within an NFA. At most 2 transitions emanate from any NFA state. 
        </member>
        <member name="F:Antlr3.Analysis.NFAState._numTransitions">
            How many transitions; 0, 1, or 2 transitions 
        </member>
        <member name="F:Antlr3.Analysis.NFAState.incidentEdgeLabel">
            For o-A->o type NFA tranitions, record the label that leads to this
            state.  Useful for creating rich error messages when we find
            insufficiently (with preds) covered states.
        </member>
        <member name="F:Antlr3.Analysis.NFAState.nfa">
            Which NFA are we in? 
        </member>
        <member name="F:Antlr3.Analysis.NFAState._decisionNumber">
            What's its decision number from 1..n? 
        </member>
        <member name="F:Antlr3.Analysis.NFAState.decisionStateType">
            Subrules (...)* and (...)+ have more than one decision point in
              the NFA created for them.  They both have a loop-exit-or-stay-in
              decision node (the loop back node).  They both have a normal
              alternative block decision node at the left edge.  The (...)* is
              worse as it even has a bypass decision (2 alts: stay in or bypass)
              node at the extreme left edge.  This is not how they get generated
              in code as a while-loop or whatever deals nicely with either.  For
              error messages (where I need to print the nondeterministic alts)
              and for interpretation, I need to use the single DFA that is created
              (for efficiency) but interpret the results differently depending
              on which of the 2 or 3 decision states uses the DFA.  For example,
              the DFA will always report alt n+1 as the exit branch for n real
              alts, so I need to translate that depending on the decision state.
            
              If decisionNumber>0 then this var tells you what kind of decision
              state it is.
        </member>
        <member name="F:Antlr3.Analysis.NFAState.enclosingRule">
            What rule do we live in? 
        </member>
        <member name="F:Antlr3.Analysis.NFAState._description">
            During debugging and for nondeterminism warnings, it's useful
            to know what relationship this node has to the original grammar.
            For example, "start of alt 1 of rule a".
        </member>
        <member name="F:Antlr3.Analysis.NFAState.associatedASTNode">
            Associate this NFAState with the corresponding GrammarAST node
            from which this node was created.  This is useful not only for
            associating the eventual lookahead DFA with the associated
            Grammar position, but also for providing users with
            nondeterminism warnings.  Mainly used by decision states to
            report line:col info.  Could also be used to track line:col
            for elements such as token refs.
        </member>
        <member name="F:Antlr3.Analysis.NFAState._eotTargetState">
            Is this state the sole target of an EOT transition? 
        </member>
        <member name="F:Antlr3.Analysis.NFAState.endOfBlockStateNumber">
            Jean Bovet needs in the GUI to know which state pairs correspond
            to the start/stop of a block.
        </member>
        <member name="M:Antlr3.Analysis.NFAState.SetTransition0(Antlr3.Analysis.Transition)">
            Used during optimization to reset a state to have the (single)
            transition another state has.
        </member>
        <member name="M:Antlr3.Analysis.NFAState.TranslateDisplayAltToWalkAlt(System.Int32)">
            The DFA decision for this NFA decision state always has
              an exit path for loops as n+1 for n alts in the loop.
              That is really useful for displaying nondeterministic alts
              and so on, but for walking the NFA to get a sequence of edge
              labels or for actually parsing, we need to get the real alt
              number.  The real alt number for exiting a loop is always 1
              as transition 0 points at the exit branch (we compute DFAs
              always for loops at the loopback state).
            
              For walking/parsing the loopback state:
             		1 2 3 display alt (for human consumption)
             		2 3 1 walk alt
            
              For walking the block start:
             		1 2 3 display alt
             		1 2 3
            
              For walking the bypass state of a (...)* loop:
             		1 2 3 display alt
             		1 1 2 all block alts map to entering loop exit means take bypass
            
              Non loop EBNF do not need to be translated; they are ignored by
              this method as decisionStateType==0.
            
              Return same alt if we can't translate.
        </member>
        <member name="M:Antlr3.Analysis.NFAState.SetDecisionASTNode(Antlr3.Tool.GrammarAST)">
            What AST node is associated with this NFAState?  When you
            set the AST node, I set the node to point back to this NFA state.
        </member>
        <member name="T:Antlr3.Analysis.NFAToDFAConverter">
            Code that embodies the NFA conversion to DFA. A new object is needed
            per DFA (also required for thread safety if multiple conversions
            launched).
        </member>
        <member name="F:Antlr3.Analysis.NFAToDFAConverter.SINGLE_THREADED_NFA_CONVERSION">
            Should ANTLR launch multiple threads to convert NFAs to DFAs?
            With a 2-CPU box, I note that it's about the same single or
            multithreaded.  Both CPU meters are going even when single-threaded
            so I assume the GC is killing us.  Could be the compiler.  When I
            run java -Xint mode, I get about 15% speed improvement with multiple
            threads.
        </member>
        <member name="F:Antlr3.Analysis.NFAToDFAConverter._work">
            A list of DFA states we still need to process during NFA conversion 
        </member>
        <member name="F:Antlr3.Analysis.NFAToDFAConverter._contextTrees">
            While converting NFA, we must track states that
            reference other rule's NFAs so we know what to do
            at the end of a rule.  We need to know what context invoked
            this rule so we can know where to continue looking for NFA
            states.  I'm tracking a context tree (record of rule invocation
            stack trace) for each alternative that could be predicted.
        </member>
        <member name="F:Antlr3.Analysis.NFAToDFAConverter._dfa">
            We are converting which DFA? 
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.ComputeStartState">
            From this first NFA state of a decision, create a DFA.
              Walk each alt in decision and compute closure from the start of that
              rule, making sure that the closure does not include other alts within
              that same decision.  The idea is to associate a specific alt number
              with the starting closure so we can trace the alt number for all states
              derived from this.  At a stop state in the DFA, we can return this alt
              number, indicating which alt is predicted.
            
              If this DFA is derived from an loop back NFA state, then the first
              transition is actually the exit branch of the loop.  Rather than make
              this alternative one, let's make this alt n+1 where n is the number of
              alts in this block.  This is nice to keep the alts of the block 1..n;
              helps with error messages.
            
              I handle nongreedy in findNewDFAStatesAndAddDFATransitions
              when nongreedy and EOT transition.  Make state with EOT emanating
              from it the accept state.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.FindNewDFAStatesAndAddDFATransitions(Antlr3.Analysis.DFAState)">
            From this node, add a d--a-->t transition for all
            labels 'a' where t is a DFA node created
            from the set of NFA states reachable from any NFA
            state in DFA state d.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.AddTransition(Antlr3.Analysis.DFAState,Antlr3.Analysis.Label,Antlr3.Analysis.DFAState,System.Collections.Generic.IDictionary{System.Int32,Antlr3.Analysis.Transition})">
            Add a transition from state d to targetState with label in normal case.
              if COLLAPSE_ALL_INCIDENT_EDGES, however, try to merge all edges from
              d to targetState; this means merging their labels.  Another optimization
              is to reduce to a single EOT edge any set of edges from d to targetState
              where there exists an EOT state.  EOT is like the wildcard so don't
              bother to test any other edges.  Example:
            
              NUM_INT
                : '1'..'9' ('0'..'9')* ('l'|'L')?
                | '0' ('x'|'X') ('0'..'9'|'a'..'f'|'A'..'F')+ ('l'|'L')?
                | '0' ('0'..'7')* ('l'|'L')?
                ;
            
              The normal decision to predict alts 1, 2, 3 is:
            
              if ( (input.LA(1)>='1' &amp;&amp; input.LA(1)&lt;='9') ) {
                   alt7=1;
              }
              else if ( input.LA(1)=='0' ) {
                  if ( input.LA(2)=='X'||input.LA(2)=='x' ) {
                      alt7=2;
                  }
                  else if ( (input.LA(2)>='0' &amp;&amp; input.LA(2)&lt;='7') ) {
                       alt7=3;
                  }
                  else if ( input.LA(2)=='L'||input.LA(2)=='l' ) {
                       alt7=3;
                  }
                  else {
                       alt7=3;
                  }
              }
              else error
            
              Clearly, alt 3 is predicted with extra work since it tests 0..7
              and [lL] before finally realizing that any character is actually
              ok at k=2.
            
              A better decision is as follows:
            
              if ( (input.LA(1)>='1' &amp;&amp; input.LA(1)&lt;='9') ) {
                  alt7=1;
              }
              else if ( input.LA(1)=='0' ) {
                  if ( input.LA(2)=='X'||input.LA(2)=='x' ) {
                      alt7=2;
                  }
                  else {
                      alt7=3;
                  }
              }
            
              The DFA originally has 3 edges going to the state the predicts alt 3,
              but upon seeing the EOT edge (the "else"-clause), this method
              replaces the old merged label (which would have (0..7|l|L)) with EOT.
              The code generator then leaves alt 3 predicted with a simple else-
              clause. :)
            
              The only time the EOT optimization makes no sense is in the Tokens
              rule.  We want EOT to truly mean you have matched an entire token
              so don't bother actually rewinding to execute that rule unless there
              are actions in that rule.  For now, since I am not preventing
              backtracking from Tokens rule, I will simply allow the optimization.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.Closure(Antlr3.Analysis.DFAState)">
            For all NFA states (configurations) merged in d,
            compute the epsilon closure; that is, find all NFA states reachable
            from the NFA states in d via purely epsilon transitions.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.Closure(Antlr3.Analysis.NFAState,System.Int32,Antlr3.Analysis.NFAContext,Antlr3.Analysis.SemanticContext,Antlr3.Analysis.DFAState,System.Boolean)">
            Where can we get from NFA state p traversing only epsilon transitions?
              Add new NFA states + context to DFA state d.  Also add semantic
              predicates to semantic context if collectPredicates is set.  We only
              collect predicates at hoisting depth 0, meaning before any token/char
              have been recognized.  This corresponds, during analysis, to the
              initial DFA start state construction closure() invocation.
            
              There are four cases of interest (the last being the usual transition):
            
               1. Traverse an edge that takes us to the start state of another
                  rule, r.  We must push this state so that if the DFA
                  conversion hits the end of rule r, then it knows to continue
                  the conversion at state following state that "invoked" r. By
                  construction, there is a single transition emanating from a rule
                  ref node.
            
               2. Reach an NFA state associated with the end of a rule, r, in the
                  grammar from which it was built.  We must add an implicit (i.e.,
                  don't actually add an epsilon transition) epsilon transition
                  from r's end state to the NFA state following the NFA state
                  that transitioned to rule r's start state.  Because there are
                  many states that could reach r, the context for a rule invocation
                  is part of a call tree not a simple stack.  When we fall off end
                  of rule, "pop" a state off the call tree and add that state's
                  "following" node to d's NFA configuration list.  The context
                  for this new addition will be the new "stack top" in the call tree.
            
               3. Like case 2, we reach an NFA state associated with the end of a
                  rule, r, in the grammar from which NFA was built.  In this case,
                  however, we realize that during this NFA->DFA conversion, no state
                  invoked the current rule's NFA.  There is no choice but to add
                  all NFA states that follow references to r's start state.  This is
                  analogous to computing the FOLLOW(r) in the LL(k) world.  By
                  construction, even rule stop state has a chain of nodes emanating
                  from it that points to every possible following node.  This case
                  is conveniently handled then by the 4th case.
            
               4. Normal case.  If p can reach another NFA state q, then add
                  q to d's configuration list, copying p's context for q's context.
                  If there is a semantic predicate on the transition, then AND it
                  with any existing semantic context.
            
               Current state p is always added to d's configuration list as it's part
               of the closure as well.
            
              When is a closure operation in a cycle condition?  While it is
              very possible to have the same NFA state mentioned twice
              within the same DFA state, there are two situations that
              would lead to nontermination of closure operation:
            
              o   Whenever closure reaches a configuration where the same state
                  with same or a suffix context already exists.  This catches
                  the IF-THEN-ELSE tail recursion cycle and things like
            
                  a : A a | B ;
            
                  the context will be $ (empty stack).
            
                  We have to check
                  larger context stacks because of (...)+ loops.  For
                  example, the context of a (...)+ can be nonempty if the
                  surrounding rule is invoked by another rule:
            
                  a : b A | X ;
                  b : (B|)+ ;  // nondeterministic by the way
            
                  The context of the (B|)+ loop is "invoked from item
                  a : . b A ;" and then the empty alt of the loop can reach back
                  to itself.  The context stack will have one "return
                  address" element and so we must check for same state, same
                  context for arbitrary context stacks.
            
                  Idea: If we've seen this configuration before during closure, stop.
                  We also need to avoid reaching same state with conflicting context.
                  Ultimately analysis would stop and we'd find the conflict, but we
                  should stop the computation.  Previously I only checked for
                  exact config.  Need to check for same state, suffix context
             		not just exact context.
            
              o   Whenever closure reaches a configuration where state p
                  is present in its own context stack.  This means that
                  p is a rule invocation state and the target rule has
                  been called before.  NFAContext.MAX_RECURSIVE_INVOCATIONS
                  (See the comment there also) determines how many times
                  it's possible to recurse; clearly we cannot recurse forever.
                  Some grammars such as the following actually require at
                  least one recursive call to correctly compute the lookahead:
            
                  a : L ID R
                    | b
                    ;
                  b : ID
                    | L a R
                    ;
            
                  Input L ID R is ambiguous but to figure this out, ANTLR
                  needs to go a->b->a->b to find the L ID sequence.
            
                  Do not allow closure to add a configuration that would
                  allow too much recursion.
            
                  This case also catches infinite left recursion.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.ClosureIsBusy(Antlr3.Analysis.DFAState,Antlr3.Analysis.NFAConfiguration)">
            A closure operation should abort if that computation has already
              been done or a computation with a conflicting context has already
              been done.  If proposed NFA config's state and alt are the same
              there is potentially a problem.  If the stack context is identical
              then clearly the exact same computation is proposed.  If a context
              is a suffix of the other, then again the computation is in an
              identical context.  ?$ and ??$ are considered the same stack.
              We could walk configurations linearly doing the comparison instead
              of a set for exact matches but it's much slower because you can't
              do a Set lookup.  I use exact match as ANTLR
              always detect the conflict later when checking for context suffixes...
              I check for left-recursive stuff and terminate before analysis to
              avoid need to do this more expensive computation.
            
              12-31-2007: I had to use the loop again rather than simple
              closureBusy.contains(proposedNFAConfiguration) lookup.  The
              semantic context should not be considered when determining if
              a closure operation is busy.  I saw a FOLLOW closure operation
              spin until time out because the predicate context kept increasing
              in size even though it's same boolean value.  This seems faster also
              because I'm not doing String.equals on the preds all the time.
            
              05-05-2008: Hmm...well, i think it was a mistake to remove the sem
              ctx check below...adding back in.  Coincides with report of ANTLR
              getting super slow: http://www.antlr.org:8888/browse/ANTLR-235
              This could be because it doesn't properly compute then resolve
              a predicate expression.  Seems to fix unit test:
              TestSemanticPredicates.testSemanticContextPreventsEarlyTerminationOfClosure()
              Changing back to Set from List.  Changed a large grammar from 8 minutes
              to 11 seconds.  Cool.  Closing ANTLR-235.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.Reach(Antlr3.Analysis.DFAState,Antlr3.Analysis.Label)">
            Given the set of NFA states in DFA state d, find all NFA states
              reachable traversing label arcs.  By definition, there can be
              only one DFA state reachable by an atom from DFA state d so we must
              find and merge all NFA states reachable via label.  Return a new
              DFAState that has all of those NFA states with their context (i.e.,
              which alt do they predict and where to return to if they fall off
              end of a rule).
            
              Because we cannot jump to another rule nor fall off the end of a rule
              via a non-epsilon transition, NFA states reachable from d have the
              same configuration as the NFA state in d.  So if NFA state 7 in d's
              configurations can reach NFA state 13 then 13 will be added to the
              new DFAState (labelDFATarget) with the same configuration as state
              7 had.
            
              This method does not see EOT transitions off the end of token rule
              accept states if the rule was invoked by somebody.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.ConvertToEOTAcceptState(Antlr3.Analysis.DFAState)">
            Walk the configurations of this DFA state d looking for the
              configuration, c, that has a transition on EOT.  State d should
              be converted to an accept state predicting the c.alt.  Blast
              d's current configuration set and make it just have config c.
            
              TODO: can there be more than one config with EOT transition?
              That would mean that two NFA configurations could reach the
              end of the token with possibly different predicted alts.
              Seems like that would be rare or impossible.  Perhaps convert
              this routine to find all such configs and give error if >1.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.AddDFAStateToWorkList(Antlr3.Analysis.DFAState)">
            Add a new DFA state to the DFA if not already present.
            If the DFA state uniquely predicts a single alternative, it
            becomes a stop state; don't add to work list.  Further, if
            there exists an NFA state predicted by > 1 different alternatives
            and with the same syn and sem context, the DFA is nondeterministic for
            at least one input sequence reaching that NFA state.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.ResolveNonDeterminisms(Antlr3.Analysis.DFAState)">
            If > 1 NFA configurations within this DFA state have identical
              NFA state and context, but differ in their predicted
              TODO update for new context suffix stuff 3-9-2005
              alternative then a single input sequence predicts multiple alts.
              The NFA decision is therefore syntactically indistinguishable
              from the left edge upon at least one input sequence.  We may
              terminate the NFA to DFA conversion for these paths since no
              paths emanating from those NFA states can possibly separate
              these conjoined twins once interwined to make things
              deterministic (unless there are semantic predicates; see below).
            
              Upon a nondeterministic set of NFA configurations, we should
              report a problem to the grammar designer and resolve the issue
              by aribitrarily picking the first alternative (this usually
              ends up producing the most natural behavior).  Pick the lowest
              alt number and just turn off all NFA configurations
              associated with the other alts. Rather than remove conflicting
              NFA configurations, I set the "resolved" bit so that future
              computations will ignore them.  In this way, we maintain the
              complete DFA state with all its configurations, but prevent
              future DFA conversion operations from pursuing undesirable
              paths.  Remember that we want to terminate DFA conversion as
              soon as we know the decision is deterministic *or*
              nondeterministic.
            
              [BTW, I have convinced myself that there can be at most one
              set of nondeterministic configurations in a DFA state.  Only NFA
              configurations arising from the same input sequence can appear
              in a DFA state.  There is no way to have another complete set
              of nondeterministic NFA configurations without another input
              sequence, which would reach a different DFA state.  Therefore,
              the two nondeterministic NFA configuration sets cannot collide
              in the same DFA state.]
            
              Consider DFA state {(s|1),(s|2),(s|3),(t|3),(v|4)} where (s|a)
              is state 's' and alternative 'a'.  Here, configuration set
              {(s|1),(s|2),(s|3)} predicts 3 different alts.  Configurations
              (s|2) and (s|3) are "resolved", leaving {(s|1),(t|3),(v|4)} as
              items that must still be considered by the DFA conversion
              algorithm in DFA.findNewDFAStatesAndAddDFATransitions().
            
              Consider the following grammar where alts 1 and 2 are no
              problem because of the 2nd lookahead symbol.  Alts 3 and 4 are
              identical and will therefore reach the rule end NFA state but
              predicting 2 different alts (no amount of future lookahead
              will render them deterministic/separable):
            
              a : A B
                | A C
                | A
                | A
                ;
            
              Here is a (slightly reduced) NFA of this grammar:
            
              (1)-A->(2)-B->(end)-EOF->(8)
               |              ^
              (2)-A->(3)-C----|
               |              ^
              (4)-A->(5)------|
               |              ^
              (6)-A->(7)------|
            
              where (n) is NFA state n.  To begin DFA conversion, the start
              state is created:
            
              {(1|1),(2|2),(4|3),(6|4)}
            
              Upon A, all NFA configurations lead to new NFA states yielding
              new DFA state:
            
              {(2|1),(3|2),(5|3),(7|4),(end|3),(end|4)}
            
              where the configurations with state end in them are added
              during the epsilon closure operation.  State end predicts both
              alts 3 and 4.  An error is reported, the latter configuration is
              flagged as resolved leaving the DFA state as:
            
              {(2|1),(3|2),(5|3),(7|4|resolved),(end|3),(end|4|resolved)}
            
              As NFA configurations are added to a DFA state during its
              construction, the reachable set of labels is computed.  Here
              reachable is {B,C,EOF} because there is at least one NFA state
              in the DFA state that can transition upon those symbols.
            
              The final DFA looks like:
            
              {(1|1),(2|2),(4|3),(6|4)}
                          |
                          v
              {(2|1),(3|2),(5|3),(7|4),(end|3),(end|4)} -B-> (end|1)
                          |                        |
                          C                        ----EOF-> (8,3)
                          |
                          v
                       (end|2)
            
              Upon AB, alt 1 is predicted.  Upon AC, alt 2 is predicted.
              Upon A EOF, alt 3 is predicted.  Alt 4 is not a viable
              alternative.
            
              The algorithm is essentially to walk all the configurations
              looking for a conflict of the form (s|i) and (s|j) for i!=j.
              Use a hash table to track state+context pairs for collisions
              so that we have O(n) to walk the n configurations looking for
              a conflict.  Upon every conflict, track the alt number so
              we have a list of all nondeterministically predicted alts. Also
              track the minimum alt.  Next go back over the configurations, setting
              the "resolved" bit for any that have an alt that is a member of
              the nondeterministic set.  This will effectively remove any alts
              but the one we want from future consideration.
            
              See resolveWithSemanticPredicates()
            
              AMBIGUOUS TOKENS
            
              With keywords and ID tokens, there is an inherit ambiguity in that
              "int" can be matched by ID also.  Each lexer rule has an EOT
              transition emanating from it which is used whenever the end of
              a rule is reached and another token rule did not invoke it.  EOT
              is the only thing that can be seen next.  If two rules are identical
              like "int" and "int" then the 2nd def is unreachable and you'll get
              a warning.  We prevent a warning though for the keyword/ID issue as
              ID is still reachable.  This can be a bit weird.  '+' rule then a
              '+'|'+=' rule will fail to match '+' for the 2nd rule.
            
              If all NFA states in this DFA state are targets of EOT transitions,
              (and there is more than one state plus no unique alt is predicted)
              then DFA conversion will leave this state as a dead state as nothing
              can be reached from this state.  To resolve the ambiguity, just do
              what flex and friends do: pick the first rule (alt in this case) to
              win.  This means you should put keywords before the ID rule.
              If the DFA state has only one NFA state then there is no issue:
              it uniquely predicts one alt. :)  Problem
              states will look like this during conversion:
            
              DFA 1:{9|1, 19|2, 14|3, 20|2, 23|2, 24|2, ...}-&lt;EOT&gt;->5:{41|3, 42|2}
            
              Worse, when you have two identical literal rules, you will see 3 alts
              in the EOT state (one for ID and one each for the identical rules).
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.ResolveByPickingMinAlt(Antlr3.Analysis.DFAState,System.Collections.Generic.ICollection{System.Int32})">
            Turn off all configurations associated with the
              set of incoming nondeterministic alts except the min alt number.
              There may be many alts among the configurations but only turn off
              the ones with problems (other than the min alt of course).
            
              If nondeterministicAlts is null then turn off all configs 'cept those
              associated with the minimum alt.
            
              Return the min alt found.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.ResolveByPickingExitAlt(Antlr3.Analysis.DFAState,System.Collections.Generic.ICollection{System.Int32})">
            Resolve state d by choosing exit alt, which is same value as the
            number of alternatives.  Return that exit alt.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.TurnOffOtherAlts(Antlr3.Analysis.DFAState,System.Int32,System.Collections.Generic.ICollection{System.Int32})">
            turn off all states associated with alts other than the good one
            (as long as they are one of the nondeterministic ones)
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.TryToResolveWithSemanticPredicates(Antlr3.Analysis.DFAState,System.Collections.Generic.ICollection{System.Int32})">
            See if a set of nondeterministic alternatives can be disambiguated
              with the semantic predicate contexts of the alternatives.
            
              Without semantic predicates, syntactic conflicts are resolved
              by simply choosing the first viable alternative.  In the
              presence of semantic predicates, you can resolve the issue by
              evaluating boolean expressions at run time.  During analysis,
              this amounts to suppressing grammar error messages to the
              developer.  NFA configurations are always marked as "to be
              resolved with predicates" so that
              DFA.findNewDFAStatesAndAddDFATransitions() will know to ignore
              these configurations and add predicate transitions to the DFA
              after adding token/char labels.
            
              During analysis, we can simply make sure that for n
              ambiguously predicted alternatives there are at least n-1
              unique predicate sets.  The nth alternative can be predicted
              with "not" the "or" of all other predicates.  NFA configurations without
              predicates are assumed to have the default predicate of
              "true" from a user point of view.  When true is combined via || with
              another predicate, the predicate is a tautology and must be removed
              from consideration for disambiguation:
            
              a : b | B ; // hoisting p1||true out of rule b, yields no predicate
              b : {p1}? B | B ;
            
              This is done down in getPredicatesPerNonDeterministicAlt().
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.GetPredicatesPerNonDeterministicAlt(Antlr3.Analysis.DFAState,System.Collections.Generic.ICollection{System.Int32})">
            Return a mapping from nondeterministc alt to combined list of predicates.
              If both (s|i|semCtx1) and (t|i|semCtx2) exist, then the proper predicate
              for alt i is semCtx1||semCtx2 because you have arrived at this single
              DFA state via two NFA paths, both of which have semantic predicates.
              We ignore deterministic alts because syntax alone is sufficient
              to predict those.  Do not include their predicates.
            
              Alts with no predicate are assumed to have {true}? pred.
            
              When combining via || with "true", all predicates are removed from
              consideration since the expression will always be true and hence
              not tell us how to resolve anything.  So, if any NFA configuration
              in this DFA state does not have a semantic context, the alt cannot
              be resolved with a predicate.
            
              If nonnull, incidentEdgeLabel tells us what NFA transition label
              we did a reach on to compute state d.  d may have insufficient
              preds, so we really want this for the error message.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.GetUnionOfPredicates(System.Collections.Generic.IDictionary{System.Int32,Antlr3.Analysis.SemanticContext})">
            OR together all predicates from the alts.  Note that the predicate
            for an alt could itself be a combination of predicates.
        </member>
        <member name="M:Antlr3.Analysis.NFAToDFAConverter.AddPredicateTransitions(Antlr3.Analysis.DFAState)">
            for each NFA config in d, look for "predicate required" sign set
              during nondeterminism resolution.
            
              Add the predicate edges sorted by the alternative number; I'm fairly
              sure that I could walk the configs backwards so they are added to
              the predDFATarget in the right order, but it's best to make sure.
              Predicates succeed in the order they are specifed.  Alt i wins
              over alt i+1 if both predicates are true.
        </member>
        <member name="T:Antlr3.Analysis.NonLLStarDecisionException">
            Used to abort DFA construction when we find non-LL(*) decision; i.e.,
            a decision that has recursion in more than a single alt.
        </member>
        <member name="F:Antlr3.Analysis.PredicateLabel._semanticContext">
            A tree of semantic predicates from the grammar AST if label==SEMPRED.
            In the NFA, labels will always be exactly one predicate, but the DFA
            may have to combine a bunch of them as it collects predicates from
            multiple NFA configurations into a single DFA state.
        </member>
        <member name="M:Antlr3.Analysis.PredicateLabel.#ctor(Antlr3.Tool.GrammarAST)">
            Make a semantic predicate label 
        </member>
        <member name="M:Antlr3.Analysis.PredicateLabel.#ctor(Antlr3.Analysis.SemanticContext)">
            Make a semantic predicates label 
        </member>
        <member name="T:Antlr3.Analysis.RuleClosureTransition">
            A transition used to reference another rule.  It tracks two targets
            really: the actual transition target and the state following the
            state that refers to the other rule.  Conversion of an NFA that
            falls off the end of a rule will be able to figure out who invoked
            that rule because of these special transitions.
        </member>
        <member name="F:Antlr3.Analysis.RuleClosureTransition._rule">
            Ptr to the rule definition object for this rule ref 
        </member>
        <member name="F:Antlr3.Analysis.RuleClosureTransition._followState">
            What node to begin computations following ref to rule 
        </member>
        <member name="T:Antlr3.Analysis.SemanticContext">
            A binary tree structure used to record the semantic context in which
              an NFA configuration is valid.  It's either a single predicate or
              a tree representing an operation tree such as: p1&amp;&amp;p2 or p1||p2.
            
              For NFA o-p1->o-p2->o, create tree AND(p1,p2).
              For NFA (1)-p1->(2)
                       |       ^
                       |       |
                      (3)-p2----
              we will have to combine p1 and p2 into DFA state as we will be
              adding NFA configurations for state 2 with two predicates p1,p2.
              So, set context for combined NFA config for state 2: OR(p1,p2).
            
              I have scoped the AND, NOT, OR, and Predicate subclasses of
              SemanticContext within the scope of this outer class.
            
              July 7, 2006: TJP altered OR to be set of operands. the Binary tree
              made it really hard to reduce complicated || sequences to their minimum.
              Got huge repeated || conditions.
        </member>
        <member name="F:Antlr3.Analysis.SemanticContext.EmptySemanticContext">
            Create a default value for the semantic context shared among all
            NFAConfigurations that do not have an actual semantic context.
            This prevents lots of if!=null type checks all over; it represents
            just an empty set of predicates.
        </member>
        <member name="P:Antlr3.Analysis.SemanticContext.GatedPredicateContext">
            Given a semantic context expression tree, return a tree with all
            nongated predicates set to true and then reduced.  So p&amp;&amp;(q||r) would
            return p&amp;&amp;r if q is nongated but p and r are gated.
        </member>
        <member name="M:Antlr3.Analysis.SemanticContext.TrackUseOfSyntacticPredicates(Antlr3.Tool.Grammar)">
            Notify the indicated grammar of any syn preds used within this context 
        </member>
        <member name="M:Antlr3.Analysis.SemanticContext.GenExpr(Antlr3.Codegen.CodeGenerator,Antlr4.StringTemplate.TemplateGroup,Antlr3.Analysis.DFA)">
            Generate an expression that will evaluate the semantic context,
            given a set of output templates.
        </member>
        <member name="F:Antlr3.Analysis.SemanticContext.Predicate._predicateAST">
            The AST node in tree created from the grammar holding the predicate 
        </member>
        <member name="F:Antlr3.Analysis.SemanticContext.Predicate._gated">
            Is this a {...}?=> gating predicate or a normal disambiguating {..}?
              If any predicate in expression is gated, then expression is considered
              gated.
            
              The simple Predicate object's predicate AST's type is used to set
              gated to true if type==GATED_SEMPRED.
        </member>
        <member name="F:Antlr3.Analysis.SemanticContext.Predicate._synpred">
            syntactic predicates are converted to semantic predicates
            but synpreds are generated slightly differently.
        </member>
        <member name="F:Antlr3.Analysis.SemanticContext.Predicate._constantValue">
            sometimes predicates are known to be true or false; we need
            a way to represent this without resorting to a target language
            value like true or TRUE.
        </member>
        <member name="M:Antlr3.Analysis.SemanticContext.Predicate.Equals(Antlr3.Analysis.SemanticContext)">
            Two predicates are the same if they are literally the same
            text rather than same node in the grammar's AST.
            Or, if they have the same constant value, return equal.
            As of July 2006 I'm not sure these are needed.
        </member>
        <member name="T:Antlr3.Analysis.State">
            A generic state machine state. 
        </member>
        <member name="F:Antlr3.Analysis.State.acceptState">
            An accept state is an end of rule state for lexers and
            parser grammar rules.
        </member>
        <member name="T:Antlr3.Analysis.StateCluster">
            A Cluster object points to the left/right (start and end) states of a
            state machine.  Used to build NFAs.
        </member>
        <member name="T:Antlr3.Analysis.Transition">
            A generic transition between any two state machine states.  It defines
            some special labels that indicate things like epsilon transitions and
            that the label is actually a set of labels or a semantic predicate.
            This is a one way link.  It emanates from a state (usually via a list of
            transitions) and has a label/target pair.  I have abstracted the notion
            of a Label to handle the various kinds of things it can be.
        </member>
        <member name="F:Antlr3.Analysis.Transition.label">
            <summary>
            What label must be consumed to transition to target
            </summary>
        </member>
        <member name="F:Antlr3.Analysis.Transition.target">
            <summary>
            The target of this transition
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Transition.Label">
            <summary>
            Gets or sets the label which must be consumed to transition to target
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Transition.Target">
            <summary>
            Gets the target state
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Transition.IsAction">
            <summary>
            Gets whether or not the transition is an action
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Transition.IsEpsilon">
            <summary>
            Gets whether or not the transition is an epsilon-transition
            </summary>
        </member>
        <member name="P:Antlr3.Analysis.Transition.IsSemanticPredicate">
            <summary>
            Gets whether or not the transition is a semantic predicate transition
            </summary>
        </member>
        <member name="F:Antlr3.AntlrTool.make">
            Don't process grammar file if generated files are newer than grammar 
        </member>
        <member name="M:Antlr3.AntlrTool.BuildRequired(System.String)">
             Checks to see if the list of outputFiles all exist, and have
             last-modified timestamps which are later than the last-modified
             timestamp of all the grammar files involved in build the output
             (imports must be checked). If these conditions hold, the method
             returns false, otherwise, it returns true.
            
             @param grammarFileName The grammar file we are checking
             @param outputFiles
             @return
        </member>
        <member name="M:Antlr3.AntlrTool.GetRootGrammar(System.String)">
            Get a grammar mentioned on the command-line and any delegates 
        </member>
        <member name="M:Antlr3.AntlrTool.GenerateRecognizer(Antlr3.Tool.Grammar)">
            Create NFA, DFA and generate code for grammar.
            Create NFA for any delegates first.  Once all NFA are created,
            it's ok to create DFA, which must check for left-recursion.  That check
            is done by walking the full NFA, which therefore must be complete.
            After all NFA, comes DFA conversion for root grammar then code gen for
            root grammar.  DFA and code gen for delegates comes next.
        </member>
        <member name="M:Antlr3.AntlrTool.SetOutputDirectory(System.String)">
            <summary>
            Set the location (base directory) where output files should be produced by the ANTLR tool.
            </summary>
            <param name="outputDirectory"></param>
        </member>
        <member name="M:Antlr3.AntlrTool.SetForceRelativeOutput(System.Boolean)">
             Used by build tools to force the output files to always be
             relative to the base output directory, even though the tool
             had to set the output directory to an absolute path as it
             cannot rely on the workign directory like command line invocation
             can.
            
             @param forceRelativeOutput true if output files hould always be relative to base output directory
        </member>
        <member name="M:Antlr3.AntlrTool.SetInputDirectory(System.String)">
             Set the base location of input files. Normally (when the tool is
             invoked from the command line), the inputDirectory is not set, but
             for build tools such as Maven, we need to be able to locate the input
             files relative to the base, as the working directory could be anywhere and
             changing workig directories is not a valid concept for JVMs because of threading and
             so on. Setting the directory just means that the getFileDirectory() method will
             try to open files relative to this input directory.
            
             @param inputDirectory Input source base directory
        </member>
        <member name="M:Antlr3.AntlrTool.GetOutputDirectory(System.String)">
             Return the location where ANTLR will generate output files for a given file. This is a
             base directory and output files will be relative to here in some cases
             such as when -o option is used and input files are given relative
             to the input directory.
            
             @param fileNameWithPath path to input source
             @return
        </member>
        <member name="M:Antlr3.AntlrTool.GetLibraryFile(System.String)">
             Name a file from the -lib dir.  Imported grammars and .tokens files
            
             If we do not locate the file in the library directory, then we try
             the location of the originating grammar.
            
             @param fileName input name we are looking for
             @return Path to file that we think shuold be the import file
            
             @throws java.io.IOException
        </member>
        <member name="M:Antlr3.AntlrTool.GetFileDirectory(System.String)">
            Return the directory containing the grammar file for this grammar.
              normally this is a relative path from current directory.  People will
              often do "java org.antlr.Tool grammars/*.g3"  So the file will be
              "grammars/foo.g3" etc...  This method returns "grammars".
            
              If we have been given a specific input directory as a base, then
              we must find the directory relative to this directory, unless the
              file name is given to us in absolute terms.
        </member>
        <member name="M:Antlr3.AntlrTool.GetImportedVocabFile(System.String)">
            Return a File descriptor for vocab file.  Look in library or
            in -o output path.  antlr -o foo T.g U.g where U needs T.tokens
            won't work unless we look in foo too. If we do not find the
            file in the lib directory then must assume that the .tokens file
            is going to be generated as part of this build and we have defined
            .tokens files so that they ALWAYS are generated in the base output
            directory, which means the current directory for the command line tool if there
            was no output directory specified.
        </member>
        <member name="M:Antlr3.AntlrTool.Panic">
            If the tool needs to panic/exit, how do we do that?
        </member>
        <member name="M:Antlr3.AntlrTool.GetCurrentTimeStamp">
            <summary>
            Return a time stamp string accurate to sec: yyyy-mm-dd hh:mm:ss
            </summary>
        </member>
        <member name="P:Antlr3.AntlrTool.GrammarFileNames">
             Provide the List of all grammar file names that the ANTLR tool will
             process or has processed.
            
             @return the grammarFileNames
        </member>
        <member name="P:Antlr3.AntlrTool.Generate_NFA_dot">
             Indicates whether ANTLR has gnerated or will generate a description of
             all the NFAs in <a href="http://www.graphviz.org">Dot format</a>
            
             @return the generate_NFA_dot
        </member>
        <member name="P:Antlr3.AntlrTool.Generate_DFA_dot">
             Indicates whether ANTLR has generated or will generate a description of
             all the NFAs in <a href="http://www.graphviz.org">Dot format</a>
            
             @return the generate_DFA_dot
        </member>
        <member name="P:Antlr3.AntlrTool.OutputDirectory">
            Return the Path to the base output directory, where ANTLR
            will generate all the output files for the current language target as
            well as any ancillary files such as .tokens vocab files.
            
            @return the output Directory
        </member>
        <member name="P:Antlr3.AntlrTool.LibraryDirectory">
             Return the Path to the directory in which ANTLR will search for ancillary
             files such as .tokens vocab files and imported grammar files.
            
             @return the lib Directory
        </member>
        <member name="P:Antlr3.AntlrTool.Debug">
             Indicate if ANTLR has generated, or will generate a debug version of the
             recognizer. Debug versions of a parser communicate with a debugger such
             as that contained in ANTLRWorks and at start up will 'hang' waiting for
             a connection on an IP port (49100 by default).
            
             @return the debug flag
        </member>
        <member name="P:Antlr3.AntlrTool.Trace">
             Indicate whether ANTLR has generated, or will generate a version of the
             recognizer that prints trace messages on entry and exit of each rule.
            
             @return the trace flag
        </member>
        <member name="P:Antlr3.AntlrTool.Profile">
             Indicates whether ANTLR has generated or will generate a version of the
             recognizer that gathers statistics about its execution, which it prints when
             it terminates.
            
             @return the profile
        </member>
        <member name="P:Antlr3.AntlrTool.Report">
             Indicates whether ANTLR has generated or will generate a report of various
             elements of the grammar analysis, once it it has finished analyzing a grammar
             file.
            
             @return the report flag
        </member>
        <member name="P:Antlr3.AntlrTool.PrintGrammar">
             Indicates whether ANTLR has printed, or will print, a version of the input grammar
             file(s) that is stripped of any action code embedded within.
            
             @return the printGrammar flag
        </member>
        <member name="P:Antlr3.AntlrTool.Depend">
             Indicates whether ANTLR has supplied, or will supply, a list of all the things
             that the input grammar depends upon and all the things that will be generated
             when that grammar is successfully analyzed.
            
             @return the depend flag
        </member>
        <member name="P:Antlr3.AntlrTool.ForceAllFilesToOutputDir">
             Indicates whether ANTLR will force all files to the output directory, even
             if the input files have relative paths from the input directory.
            
             @return the forceAllFilesToOutputDir flag
        </member>
        <member name="P:Antlr3.AntlrTool.Verbose">
             Indicates whether ANTLR will be verbose when analyzing grammar files, such as
             displaying the names of the files it is generating and similar information.
            
             @return the verbose flag
        </member>
        <member name="P:Antlr3.AntlrTool.MessageFormat">
            Gets or sets the current setting of the message format descriptor.
        </member>
        <member name="P:Antlr3.AntlrTool.NumErrors">
            Returns the number of errors that the analysis/processing threw up.
            @return Error count
        </member>
        <member name="P:Antlr3.AntlrTool.Make">
             Indicate whether the tool will analyze the dependencies of the provided grammar
             file list and ensure that grammars with dependencies are built
             after any of the other gramamrs in the list that they are dependent on. Setting
             this option also has the side effect that any grammars that are includes for other
             grammars in the list are excluded from individual analysis, which allows the caller
             to invoke the tool via org.antlr.tool -make *.g and not worry about the inclusion
             of grammars that are just includes for other grammars or what order the grammars
             appear on the command line.
            
             This option was coded to make life easier for tool integration (such as Maven) but
             may also be useful at the command line.
            
             @return true if the tool is currently configured to analyze and sort grammar files.
        </member>
        <member name="T:Antlr3.Codegen.CodeGenerator">
            ANTLR's code generator.
            
              Generate recognizers derived from grammars.  Language independence
              achieved through the use of TemplateGroup objects.  All output
              strings are completely encapsulated in the group files such as Java.stg.
              Some computations are done that are unused by a particular language.
              This generator just computes and sets the values into the templates;
              the templates are free to use or not use the information.
            
              To make a new code generation target, define X.stg for language X
              by copying from existing Y.stg most closely releated to your language;
              e.g., to do CSharp.stg copy Java.stg.  The template group file has a
              bunch of templates that are needed by the code generator.  You can add
              a new target w/o even recompiling ANTLR itself.  The language=X option
              in a grammar file dictates which templates get loaded/used.
            
              Some language like C need both parser files and header files.  Java needs
              to have a separate file for the cyclic DFA as ANTLR generates bytecodes
              directly (which cannot be in the generated parser Java file).  To facilitate
              this,
            
             cyclic can be in same file, but header, output must be searpate.  recognizer
              is in outptufile.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.DefaultMaxSwitchCaseLabels">
            When generating SWITCH statements, some targets might need to limit
            the size (based upon the number of case labels).  Generally, this
            limit will be hit only for lexers where wildcard in a UNICODE
            vocabulary environment would generate a SWITCH with 65000 labels.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator._grammar">
            Which grammar are we generating code for?  Each generator
            is attached to a specific grammar.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator._language">
            What language are we generating? 
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator._target">
            The target specifies how to write out files and do other language
            specific actions.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator._templates">
            Where are the templates this generator should use to generate code? 
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.baseTemplates">
            The basic output templates without AST or templates stuff; this will be
            the templates loaded for the language such as Java.stg *and* the Dbg
            stuff if turned on.  This is used for generating syntactic predicates.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.uniqueLabelNumber">
            Used to create unique labels 
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.tool">
            A reference to the ANTLR tool so we can learn about output directories
            and such.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.debug">
            Generate debugging event method calls 
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.trace">
            Create a Tracer object and make the recognizer invoke this. 
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.profile">
            Track runtime parsing information about decisions etc...
            This requires the debugging event mechanism to work.
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator._acyclicDFAGenerator">
            I have factored out the generation of acyclic DFAs to separate class 
        </member>
        <member name="F:Antlr3.Codegen.CodeGenerator.VocabFileExtension">
            I have factored out the generation of cyclic DFAs to separate class 
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.LoadTemplates(System.String)">
            load the main language.stg template group file 
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenRecognizer">
            Given the grammar to which we are attached, walk the AST associated
              with that grammar to create NFAs.  Then create the DFAs for all
              decision points in the grammar by converting the NFAs to DFAs.
              Finally, walk the AST again to generate code.
            
              Either 1 or 2 files are written:
            
             		recognizer: the main parser/lexer/treewalker item
             		header file: language like C/C++ need extern definitions
            
              The target, such as JavaTarget, dictates which files get written.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.VerifyActionScopesOkForTarget(System.Collections.Generic.IDictionary{System.String,System.Collections.Generic.IDictionary{System.String,System.Object}})">
            Some targets will have some extra scopes like C++ may have
            '@headerfile:name {action}' or something.  Make sure the
            target likes the scopes in action table.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.TranslateActionAttributeReferences(System.Collections.Generic.IDictionary{System.String,System.Collections.Generic.IDictionary{System.String,System.Object}})">
            Actions may reference $x::y attributes, call translateAction on
            each action and replace that action in the Map.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.TranslateActionAttributeReferencesForSingleScope(Antlr3.Tool.Rule,System.Collections.Generic.IDictionary{System.String,System.Object})">
            Use for translating rule @init{...} actions that have no scope 
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenerateLocalFollow(Antlr3.Tool.GrammarAST,System.String,System.String,System.Int32)">
            Error recovery in ANTLR recognizers.
            
              Based upon original ideas:
            
              Algorithms + Data Structures = Programs by Niklaus Wirth
            
              and
            
              A note on error recovery in recursive descent parsers:
              http://portal.acm.org/citation.cfm?id=947902.947905
            
              Later, Josef Grosch had some good ideas:
              Efficient and Comfortable Error Recovery in Recursive Descent Parsers:
              ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip
            
              Like Grosch I implemented local FOLLOW sets that are combined at run-time
              upon error to avoid parsing overhead.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenLookaheadDecision(Antlr4.StringTemplate.Template,Antlr3.Analysis.DFA)">
            Generate code that computes the predicted alt given a DFA.  The
              recognizerST can be either the main generated recognizerTemplate
              for storage in the main parser file or a separate file.  It's up to
              the code that ultimately invokes the codegen.g grammar rule.
            
              Regardless, the output file and header file get a copy of the DFAs.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenerateSpecialState(Antlr3.Analysis.DFAState)">
            A special state is huge (too big for state tables) or has a predicated
            edge.  Generate a simple if-then-else.  Cannot be an accept state as
            they have no emanating edges.  Don't worry about switch vs if-then-else
            because if you get here, the state is super complicated and needs an
            if-then-else.  This is used by the new DFA scheme created June 2006.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenLabelExpr(Antlr4.StringTemplate.TemplateGroup,Antlr3.Analysis.Transition,System.Int32)">
            Generate an expression for traversing an edge. 
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenSetExpr(Antlr4.StringTemplate.TemplateGroup,Antlr3.Misc.IIntSet,System.Int32,System.Boolean)">
            For intervals such as [3..3, 30..35], generate an expression that
            tests the lookahead similar to LA(1)==3 || (LA(1)>=30&amp;&amp;LA(1)&lt;=35)
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenTokenTypeConstants(Antlr4.StringTemplate.Template)">
            Set attributes tokens and literals attributes in the incoming
            code template.  This is not the token vocab interchange file, but
            rather a list of token type ID needed by the recognizer.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenTokenTypeNames(Antlr4.StringTemplate.Template)">
            Generate a token names table that maps token type to a printable
            name: either the label like INT or the literal like "begin".
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GetTokenTypeAsTargetLabel(System.Int32)">
            Get a meaningful name for a token type useful during code generation.
            Literals without associated names are converted to the string equivalent
            of their integer values. Used to generate x==ID and x==34 type comparisons
            etc...  Essentially we are looking for the most obvious way to refer
            to a token type in the generated code.  If in the lexer, return the
            char literal translated to the target language.  For example, ttype=10
            will yield '\n' from the getTokenDisplayName method.  That must
            be converted to the target languages literals.  For most C-derived
            languages no translation is needed.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GenTokenVocabOutput">
            Generate a token vocab file with all the token names/types.  For example:
              ID=7
              FOR=8
              'for'=8
            
              This is independent of the target language; used by antlr internally
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.TranslateArgAction(System.String,Antlr3.Tool.GrammarAST)">
            Translate an action like [3,"foo",a[3]] and return a List of the
            translated actions.  Because actions are themselves translated to a list
            of chunks, must cat together into a StringTemplate>.  Don't translate
            to strings early as we need to eval templates in context.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GetListOfArgumentsFromAction(System.String,System.Int32,System.Int32,System.Int32,System.Collections.Generic.IList{System.String})">
            Given an arg action like
            
              [x, (*a).foo(21,33), 3.2+1, '\n',
              "a,oo\nick", {bl, "fdkj"eck}, ["cat\n,", x, 43]]
            
              convert to a list of arguments.  Allow nested square brackets etc...
              Set separatorChar to ';' or ',' or whatever you want.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.TranslateTemplateConstructor(System.String,System.Int32,Antlr.Runtime.IToken,System.String)">
            Given a template constructor action like %foo(a={...}) in
            an action, translate it to the appropriate template constructor
            from the templateLib. This translates a *piece* of the action.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GetRecognizerFileName(System.String,Antlr3.Tool.GrammarType)">
            Generate TParser.java and TLexer.java from T.g if combined, else
            just use T.java as output regardless of type.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.GetVocabFileName">
            What is the name of the vocab file generated for this grammar?
            Returns null if no .tokens file should be generated.
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.CanGenerateSwitch(Antlr3.Analysis.DFAState)">
            You can generate a switch rather than if-then-else for a DFA state
            if there are no semantic predicates and the number of edge label
            values is small enough; e.g., don't generate a switch for a state
            containing an edge label such as 20..52330 (the resulting byte codes
            would overflow the method 65k limit probably).
        </member>
        <member name="M:Antlr3.Codegen.CodeGenerator.CreateUniqueLabel(System.String)">
            Create a label to track a token / rule reference's result.
            Technically, this is a place where I break model-view separation
            as I am creating a variable name that could be invalid in a
            target language, however, label ::= &lt;ID&gt;&lt;INT&gt; is probably ok in
            all languages we care about.
        </member>
        <member name="T:Antlr3.Codegen.Target">
            The code generator for ANTLR can usually be retargeted just by providing
              a new X.stg file for language X, however, sometimes the files that must
              be generated vary enough that some X-specific functionality is required.
              For example, in C, you must generate header files whereas in Java you do not.
              Other languages may want to keep DFA separate from the main
              generated recognizer file.
            
              The notion of a Code Generator target abstracts out the creation
              of the various files.  As new language targets get added to the ANTLR
              system, this target class may have to be altered to handle more
              functionality.  Eventually, just about all language generation issues
              will be expressible in terms of these methods.
            
              If org.antlr.codegen.XTarget class exists, it is used else
              Target base class is used.  I am using a superclass rather than an
              interface for this target concept because I can add functionality
              later without breaking previously written targets (extra interface
              methods would force adding dummy functions to all code generator
              target classes).
            
        </member>
        <member name="F:Antlr3.Codegen.Target.targetCharValueEscape">
            For pure strings of Java 16-bit unicode char, how can we display
              it in the target language as a literal.  Useful for dumping
              predicates and such that may refer to chars that need to be escaped
              when represented as strings.  Also, templates need to be escaped so
              that the target language can hold them as a string.
            
              I have defined (via the constructor) the set of typical escapes,
              but your Target subclass is free to alter the translated chars or
              add more definitions.  This is nonstatic so each target can have
              a different set in memory at same time.
        </member>
        <member name="M:Antlr3.Codegen.Target.IsValidActionScope(Antlr3.Tool.GrammarType,System.String)">
            Is scope in @scope::name {action} valid for this kind of grammar?
            Targets like C++ may want to allow new scopes like headerfile or
            some such.  The action names themselves are not policed at the
            moment so targets can add template actions w/o having to recompile
            ANTLR.
        </member>
        <member name="M:Antlr3.Codegen.Target.GetTokenTypeAsTargetLabel(Antlr3.Codegen.CodeGenerator,System.Int32)">
            Target must be able to override the labels used for token types 
        </member>
        <member name="M:Antlr3.Codegen.Target.GetTargetCharLiteralFromANTLRCharLiteral(Antlr3.Codegen.CodeGenerator,System.String)">
            Convert from an ANTLR char literal found in a grammar file to
              an equivalent char literal in the target language.  For most
              languages, this means leaving 'x' as 'x'.  Actually, we need
              to escape '\u000A' so that it doesn't get converted to \n by
              the compiler.  Convert the literal to the char value and then
              to an appropriate target char literal.
            
              Expect single quotes around the incoming literal.
        </member>
        <member name="M:Antlr3.Codegen.Target.GetTargetStringLiteralFromANTLRStringLiteral(Antlr3.Codegen.CodeGenerator,System.String)">
            Convert from an ANTLR string literal found in a grammar file to
             an equivalent string literal in the target language.  For Java, this
             is the translation 'a\n"' -> "a\n\"".  Expect single quotes
             around the incoming literal.  Just flip the quotes and replace
             double quotes with \"
            
             Note that we have decided to allow poeple to use '\"' without
             penalty, so we must build the target string in a loop as Utils.replae
             cannot handle both \" and " without a lot of messing around.
            
        </member>
        <member name="M:Antlr3.Codegen.Target.GetTargetStringLiteralFromString(System.String,System.Boolean)">
            Given a random string of Java unicode chars, return a new string with
              optionally appropriate quote characters for target language and possibly
              with some escaped characters.  For example, if the incoming string has
              actual newline characters, the output of this method would convert them
              to the two char sequence \n for Java, C, C++, ...  The new string has
              double-quotes around it as well.  Example String in memory:
            
                 a"[newlinechar]b'c[carriagereturnchar]d[tab]e\f
            
              would be converted to the valid Java s:
            
                 "a\"\nb'c\rd\te\\f"
            
              or
            
                 a\"\nb'c\rd\te\\f
            
              depending on the quoted arg.
        </member>
        <member name="M:Antlr3.Codegen.Target.GetTarget64BitStringFromValue(System.UInt64)">
            Convert long to 0xNNNNNNNNNNNNNNNN by default for spitting out
            with bitsets.  I.e., convert bytes to hex string.
        </member>
        <member name="M:Antlr3.Codegen.Target.GetMaxCharValue(Antlr3.Codegen.CodeGenerator)">
            Some targets only support ASCII or 8-bit chars/strings.  For example,
            C++ will probably want to return 0xFF here.
        </member>
        <member name="M:Antlr3.Codegen.Target.PostProcessAction(System.Collections.Generic.IList{System.Object},Antlr.Runtime.IToken)">
            Give target a chance to do some postprocessing on actions.
            Python for example will have to fix the indention.
        </member>
        <member name="T:Antlr3.Grammars.ActionAnalysisLexer">
            We need to set Rule.referencedPredefinedRuleAttributes before
            code generation.  This filter looks at an action in context of
            its rule and outer alternative number and figures out which
            rules have predefined prefs referenced.  I need this so I can
            remove unusued labels.  This also tracks, for labeled rules,
            which are referenced by actions.
        </member>
        <member name="M:Antlr3.Grammars.ActionTranslator.TranslateToChunks">
            Return a list of strings and StringTemplate objects that
            represent the translated action.
        </member>
        <member name="M:Antlr3.Grammars.ActionTranslator.GetRuleLabelAttribute(System.String,System.String)">
            For \$rulelabel.name, return the Attribute found for name.  It
            will be a predefined property or a return value.
        </member>
        <member name="T:Antlr3.Grammars.ANTLRParser">
            Read in an ANTLR grammar and build an AST.  Try not to do
              any actions, just build the tree.
            
              The phases are:
            
            		antlr.g (this file)
            		assign.types.g
            		define.g
            		buildnfa.g
            		antlr.print.g (optional)
            		codegen.g
            
              Terence Parr
              University of San Francisco
              2005
        </member>
        <member name="M:Antlr3.Grammars.ANTLRParser.CreateBlockFromDupAlt(Antlr3.Tool.GrammarAST)">
            Create a copy of the alt and make it into a BLOCK; all actions,
            labels, tree operators, rewrites are removed.
        </member>
        <member name="M:Antlr3.Grammars.ANTLRParser.PrefixWithSynPred(Antlr3.Tool.GrammarAST)">
            Rewrite alt to have a synpred as first element;
            (xxx)=>xxx
            but only if they didn't specify one manually.
        </member>
        <member name="T:Antlr3.Grammars.ANTLRTreePrinter">
            Print out a grammar (no pretty printing).
            
              Terence Parr
              University of San Francisco
              August 19, 2003
        </member>
        <member name="M:Antlr3.Grammars.ANTLRTreePrinter.Normalize(System.String)">
            Normalize a grammar print out by removing all double spaces
              and trailing/beginning stuff.  FOr example, convert
            
              ( A  |  B  |  C )*
            
              to
            
              ( A | B | C )*
        </member>
        <member name="T:Antlr3.Grammars.AssignTokenTypesWalker">
            [Warning: TJP says that this is probably out of date as of 11/19/2005,
               but since it's probably still useful, I'll leave in.  Don't have energy
               to update at the moment.]
            
              Compute the token types for all literals and rules etc..  There are
              a few different cases to consider for grammar types and a few situations
              within.
            
              CASE 1 : pure parser grammar
            	a) Any reference to a token gets a token type.
              b) The tokens section may alias a token name to a string or char
            
              CASE 2 : pure lexer grammar
              a) Import token vocabulary if available. Set token types for any new tokens
                 to values above last imported token type
              b) token rule definitions get token types if not already defined
              c) literals do NOT get token types
            
              CASE 3 : merged parser / lexer grammar
            	a) Any char or string literal gets a token type in a parser rule
              b) Any reference to a token gets a token type if not referencing
                 a fragment lexer rule
              c) The tokens section may alias a token name to a string or char
                 which must add a rule to the lexer
              d) token rule definitions get token types if not already defined
              e) token rule definitions may also alias a token name to a literal.
                 E.g., Rule 'FOR : "for";' will alias FOR to "for" in the sense that
                 references to either in the parser grammar will yield the token type
            
              What this pass does:
            
              0. Collects basic info about the grammar like grammar name and type;
                 Oh, I have go get the options in case they affect the token types.
                 E.g., tokenVocab option.
                 Imports any token vocab name/type pairs into a local hashtable.
              1. Finds a list of all literals and token names.
              2. Finds a list of all token name rule definitions;
                 no token rules implies pure parser.
              3. Finds a list of all simple token rule defs of form "&lt;NAME&gt; : &lt;literal&gt;;"
                 and aliases them.
              4. Walks token names table and assign types to any unassigned
              5. Walks aliases and assign types to referenced literals
              6. Walks literals, assigning types if untyped
              4. Informs the Grammar object of the type definitions such as:
                 g.defineToken(&lt;charliteral&gt;, ttype);
                 g.defineToken(&lt;stringliteral&gt;, ttype);
                 g.defineToken(&lt;tokenID&gt;, ttype);
                 where some of the ttype values will be the same for aliases tokens.
        </member>
        <member name="T:Antlr3.Grammars.CodeGenTreeWalker">
            Walk a grammar and generate code by gradually building up
              a bigger and bigger Template.
            
              Terence Parr
              University of San Francisco
              June 15, 2004
        </member>
        <member name="F:Antlr3.Grammars.CodeGenTreeWalker.recognizerST">
            The overall lexer/parser template; simulate dynamically scoped
            attributes by making this an instance var of the walker.
        </member>
        <member name="M:Antlr3.Grammars.CodeGenTreeWalker.GetSTSuffix(Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST,System.String)">
            Return a non-empty template name suffix if the token is to be
            tracked, added to a tree, or both.
        </member>
        <member name="M:Antlr3.Grammars.CodeGenTreeWalker.GetTokenTypesAsTargetLabels(System.Collections.Generic.HashSet{Antlr3.Tool.GrammarAST})">
            Convert rewrite AST lists to target labels list 
        </member>
        <member name="M:Antlr3.Grammars.DefineGrammarItemsWalker.TrimGrammar">
            Remove any lexer rules from a COMBINED; already passed to lexer 
        </member>
        <member name="T:Antlr3.Grammars.LeftRecursiveRuleWalker">
            Find left-recursive rules 
        </member>
        <member name="T:Antlr3.Grammars.TreeToNFAConverter">
            Build an NFA from a tree representing an ANTLR grammar. 
        </member>
        <member name="F:Antlr3.Grammars.TreeToNFAConverter.factory">
            Factory used to create nodes and submachines 
        </member>
        <member name="F:Antlr3.Grammars.TreeToNFAConverter.nfa">
            Which NFA object are we filling in? 
        </member>
        <member name="F:Antlr3.Grammars.TreeToNFAConverter.grammar">
            Which grammar are we converting an NFA for? 
        </member>
        <member name="T:Antlr3.Misc.Barrier">
            A very simple barrier wait.  Once a thread has requested a
            wait on the barrier with waitForRelease, it cannot fool the
            barrier into releasing by "hitting" the barrier multiple times--
            the thread is blocked on the wait().
        </member>
        <member name="M:Antlr3.Misc.Barrier.Action">
            What to do when everyone reaches barrier 
        </member>
        <member name="T:Antlr3.Misc.BitSet">
            A BitSet to replace java.util.BitSet.
            
             Primary differences are that most set operators return new sets
             as opposed to oring and anding "in place".  Further, a number of
             operations were added.  I cannot contain a BitSet because there
             is no way to access the internal bits (which I need for speed)
             and, because it is final, I cannot subclass to add functionality.
             Consider defining set degree.  Without access to the bits, I must
             call a method n times to test the ith bit...ack!
            
             Also seems like or() from util is wrong when size of incoming set is bigger
             than this.bits.length.
            
             @author Terence Parr
        </member>
        <member name="F:Antlr3.Misc.BitSet._bits">
            The actual data bits 
        </member>
        <member name="M:Antlr3.Misc.BitSet.#ctor">
            Construct a bitset of size one word (64 bits) 
        </member>
        <member name="M:Antlr3.Misc.BitSet.#ctor(System.UInt64[])">
            Construction from a static array of longs 
        </member>
        <member name="M:Antlr3.Misc.BitSet.#ctor(System.Int32)">
            Construct a bitset given the size
            @param nbits The size of the bitset in bits
        </member>
        <member name="P:Antlr3.Misc.BitSet.LengthInLongWords">
            return how much space is being used by the bits array not
            how many actually have member bits on.
        </member>
        <member name="M:Antlr3.Misc.BitSet.Add(System.Int32)">
            or this element into this set (grow as necessary to accommodate) 
        </member>
        <member name="M:Antlr3.Misc.BitSet.GrowToInclude(System.Int32)">
            Grows the set to a larger number of bits.
            @param bit element that must fit in set
        </member>
        <member name="M:Antlr3.Misc.BitSet.GetSingleElement">
            Get the first element you find and return it.  Return Label.INVALID
            otherwise.
        </member>
        <member name="M:Antlr3.Misc.BitSet.NotInPlace(System.Int32)">
            complement bits in the range 0..maxBit. 
        </member>
        <member name="M:Antlr3.Misc.BitSet.NotInPlace(System.Int32,System.Int32)">
            complement bits in the range minBit..maxBit.
        </member>
        <member name="M:Antlr3.Misc.BitSet.Or(Antlr3.Misc.IIntSet)">
            return this | a in a new set 
        </member>
        <member name="M:Antlr3.Misc.BitSet.SetSize(System.Int32)">
            Sets the size of a set.
            @param nwords how many words the new set should be
        </member>
        <member name="M:Antlr3.Misc.BitSet.Subset(Antlr3.Misc.BitSet)">
            Is this contained within a? 
        </member>
        <member name="M:Antlr3.Misc.BitSet.SubtractInPlace(Antlr3.Misc.BitSet)">
            Subtract the elements of 'a' from 'this' in-place.
            Basically, just turn off all bits of 'this' that are in 'a'.
        </member>
        <member name="M:Antlr3.Misc.BitSet.ToString(Antlr3.Tool.Grammar)">
            Transform a bit set into a string by formatting each element as an integer
            separator The string to put in between elements
            @return A commma-separated list of values
        </member>
        <member name="M:Antlr3.Misc.BitSet.ToString(System.String,System.Collections.IList)">
            Create a string representation where instead of integer elements, the
            ith element of vocabulary is displayed instead.  Vocabulary is a Vector
            of Strings.
            separator The string to put in between elements
            @return A commma-separated list of character constants.
        </member>
        <member name="M:Antlr3.Misc.BitSet.ToStringOfHalfWords">
            Dump a comma-separated list of the words making up the bit set.
            Split each 64 bit number into two more manageable 32 bit numbers.
            This generates a comma-separated list of C++-like unsigned long constants.
        </member>
        <member name="M:Antlr3.Misc.BitSet.ToStringOfWords">
            Dump a comma-separated list of the words making up the bit set.
            This generates a comma-separated list of Java-like long int constants.
        </member>
        <member name="F:Antlr3.Misc.Graph`1.nodes">
            Map from node payload to node containing it 
        </member>
        <member name="M:Antlr3.Misc.Graph`1.Sort">
            DFS-based topological sort.  A valid sort is the reverse of
              the post-order DFA traversal.  Amazingly simple but true.
              For sorting, I'm not following convention here since ANTLR
              needs the opposite.  Here's what I assume for sorting:
            
                If there exists an edge u -> v then u depends on v and v
                must happen before u.
            
              So if this gives nonreversed postorder traversal, I get the order
              I want.
        </member>
        <member name="T:Antlr3.Misc.IIntSet">
            A generic set of ints that has an efficient implementation, BitSet,
              which is a compressed bitset and is useful for ints that
              are small, for example less than 500 or so, and w/o many ranges.  For
              ranges with large values like unicode char sets, this is not very efficient.
              Consider using IntervalSet.  Not all methods in IntervalSet are implemented.
            
              @see org.antlr.misc.BitSet
              @see org.antlr.misc.IntervalSet
        </member>
        <member name="M:Antlr3.Misc.IIntSet.AddAll(Antlr3.Misc.IIntSet)">
            Add all elements from incoming set to this set.  Can limit
            to set of its own type.
        </member>
        <member name="M:Antlr3.Misc.IIntSet.And(Antlr3.Misc.IIntSet)">
            Return the intersection of this set with the argument, creating
            a new set.
        </member>
        <member name="T:Antlr3.Misc.Interval">
            An immutable inclusive interval a..b 
        </member>
        <member name="M:Antlr3.Misc.Interval.StartsBeforeDisjoint(Antlr3.Misc.Interval)">
            Does this start completely before other? Disjoint 
        </member>
        <member name="M:Antlr3.Misc.Interval.StartsBeforeNonDisjoint(Antlr3.Misc.Interval)">
            Does this start at or before other? Nondisjoint 
        </member>
        <member name="M:Antlr3.Misc.Interval.StartsAfter(Antlr3.Misc.Interval)">
            Does this.a start after other.b? May or may not be disjoint 
        </member>
        <member name="M:Antlr3.Misc.Interval.StartsAfterDisjoint(Antlr3.Misc.Interval)">
            Does this start completely after other? Disjoint 
        </member>
        <member name="M:Antlr3.Misc.Interval.StartsAfterNonDisjoint(Antlr3.Misc.Interval)">
            Does this start after other? NonDisjoint 
        </member>
        <member name="M:Antlr3.Misc.Interval.Disjoint(Antlr3.Misc.Interval)">
            Are both ranges disjoint? I.e., no overlap? 
        </member>
        <member name="M:Antlr3.Misc.Interval.Adjacent(Antlr3.Misc.Interval)">
            Are two intervals adjacent such as 0..41 and 42..42? 
        </member>
        <member name="M:Antlr3.Misc.Interval.Union(Antlr3.Misc.Interval)">
            Return the interval computed from combining this and other 
        </member>
        <member name="M:Antlr3.Misc.Interval.Intersection(Antlr3.Misc.Interval)">
            Return the interval in common between this and o 
        </member>
        <member name="M:Antlr3.Misc.Interval.DifferenceNotProperlyContained(Antlr3.Misc.Interval)">
            Return the interval with elements from this not in other;
            other must not be totally enclosed (properly contained)
            within this, which would result in two disjoint intervals
            instead of the single one returned by this method.
        </member>
        <member name="T:Antlr3.Misc.IntervalSet">
            A set of integers that relies on ranges being common to do
              "run-length-encoded" like compression (if you view an IntSet like
              a BitSet with runs of 0s and 1s).  Only ranges are recorded so that
              a few ints up near value 1000 don't cause massive bitsets, just two
              integer intervals.
            
              element values may be negative.  Useful for sets of EPSILON and EOF.
            
              0..9 char range is index pair ['\u0030','\u0039'].
              Multiple ranges are encoded with multiple index pairs.  Isolated
              elements are encoded with an index pair where both intervals are the same.
            
              The ranges are ordered and disjoint so that 2..6 appears before 101..103.
        </member>
        <member name="F:Antlr3.Misc.IntervalSet.intervals">
            The list of sorted, disjoint intervals. 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.#ctor">
            Create a set with no elements 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Of(System.Int32)">
            Create a set with a single element, el. 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Of(System.Int32,System.Int32)">
            Create a set with all ints within range [a..b] (inclusive) 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Add(System.Int32)">
            Add a single element to the set.  An isolated element is stored
            as a range el..el.
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Add(System.Int32,System.Int32)">
            Add interval; i.e., add all integers from a to b to set.
            If b&lt;a, do nothing.
            Keep list in sorted order (by left range value).
            If overlap, combine ranges.  For example,
            If this is {1..5, 10..20}, adding 6..7 yields
            {1..5, 6..7, 10..20}.  Adding 4..8 yields {1..8, 10..20}.
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Complement(Antlr3.Misc.Interval)">
            Given the set of possible values (rather than, say UNICODE or MAXINT),
              return a new set containing all elements in vocabulary, but not in
              this.  The computation is (vocabulary - this).
            
              'this' is assumed to be either a subset or equal to vocabulary.
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Subtract(Antlr3.Misc.IIntSet)">
            Compute this-other via this&amp;~other.
            Return a new set containing all elements in this but not in other.
            other is assumed to be a subset of this;
            anything that is in other but not in this will be ignored.
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Or(Antlr3.Misc.IIntSet)">
            TODO: implement this! 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.And(Antlr3.Misc.IIntSet)">
            Return a new set with the intersection of this set with other.  Because
            the intervals are sorted, we can use an iterator for each list and
            just walk them together.  This is roughly O(min(n,m)) for interval
            list lengths n and m.
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Contains(System.Int32)">
            Is el in any range of this set? 
        </member>
        <member name="P:Antlr3.Misc.IntervalSet.IsNil">
            return true if this set has no members 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.GetSingleElement">
            If this set is a single integer, return it otherwise Label.INVALID 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.GetMinElement">
            Return minimum element >= 0 
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Equals(System.Object)">
            Are two IntervalSets equal?  Because all intervals are sorted
            and disjoint, equals is a simple linear walk over both lists
            to make sure they are the same.  Interval.equals() is used
            by the List.equals() method to check the ranges.
        </member>
        <member name="M:Antlr3.Misc.IntervalSet.Get(System.Int32)">
            Get the ith element of ordered set.  Used only by RandomPhrase so
            don't bother to implement if you're not doing that for a new
            ANTLR code gen target.
        </member>
        <member name="T:Antlr3.Misc.MultiMap`2">
            A hash table that maps a key to a list of elements not just a single. 
        </member>
        <member name="T:Antlr3.Misc.OrderedHashSet`1">
            A HashMap that remembers the order that the elements were added.
            You can alter the ith element with this[i]=value too :)  Unique list.
            I need the replace/set-element-i functionality so I'm subclassing
            OrderedHashSet.
        </member>
        <member name="F:Antlr3.Misc.OrderedHashSet`1._elements">
            Track the elements as they are added to the set 
        </member>
        <member name="M:Antlr3.Misc.OrderedHashSet`1.Add(`0)">
            Add a value to list; keep in hashtable for consistency also;
            Key is object itself.  Good for say asking if a certain string is in
            a list of strings.
        </member>
        <member name="M:Antlr3.Misc.OrderedHashSet`1.GetElements">
            Return the List holding list of table elements.  Note that you are
            NOT getting a copy so don't write to the list.
        </member>
        <member name="M:Antlr3.Misc.Utils.integer(System.Int32)">
            Integer objects are immutable so share all Integers with the
            same value up to some max size.  Use an array as a perfect hash.
            Return shared object for 0..INTEGER_POOL_MAX_VALUE or a new
            Integer object with x in it.
        </member>
        <member name="M:Antlr3.Misc.Utils.replace(System.String,System.String,System.String)">
            Given a source string, src,
                        a string to replace, replacee,
                        and a string to replace with, replacer,
                        return a new string w/ the replacing done.
                        You can use replacer==null to remove replacee from the string.
            
                        This should be faster than Java's String.replaceAll as that one
                        uses regex (I only want to play with strings anyway).
        </member>
        <member name="T:Antlr3.Tool.AssignTokenTypesBehavior">
            Move all of the functionality from assign.types.g grammar file. 
        </member>
        <member name="F:Antlr3.Tool.AssignTokenTypesBehavior.tokenRuleDefs">
            Track actual lexer rule defs so we don't get repeated token defs in
            generated lexer.
        </member>
        <member name="M:Antlr3.Tool.AssignTokenTypesBehavior.TrackString(Antlr3.Tool.GrammarAST)">
            Track string literals (could be in tokens{} section) 
        </member>
        <member name="T:Antlr3.Tool.Attribute">
            Track the names of attributes define in arg lists, return values,
            scope blocks etc...
        </member>
        <member name="P:Antlr3.Tool.Attribute.Decl">
            The entire declaration such as "String foo;" 
        </member>
        <member name="P:Antlr3.Tool.Attribute.Type">
            The type; might be empty such as for Python which has no static typing 
        </member>
        <member name="P:Antlr3.Tool.Attribute.Name">
            The name of the attribute "foo" 
        </member>
        <member name="P:Antlr3.Tool.Attribute.InitValue">
            The optional attribute intialization expression 
        </member>
        <member name="M:Antlr3.Tool.Attribute.ExtractAttribute(System.String)">
            For decls like "String foo" or "char *foo32[3]" compute the ID
              and type declarations.  Also handle "int x=3" and 'T t = new T("foo")'
              but if the separator is ',' you cannot use ',' in the initvalue.
              AttributeScope.addAttributes takes care of the separation so we are
              free here to use from '=' to end of string as the expression.
            
              Set name, type, initvalue, and full decl instance vars.
        </member>
        <member name="T:Antlr3.Tool.AttributeScope">
            Track the attributes within a scope.  A named scoped has just its list
            of attributes.  Each rule has potentially 3 scopes: return values,
            parameters, and an implicitly-named scope (i.e., a scope defined in a rule).
            Implicitly-defined scopes are named after the rule; rules and scopes then
            must live in the same name space--no collisions allowed.
        </member>
        <member name="F:Antlr3.Tool.AttributeScope.tokenScope">
            All token scopes (token labels) share the same fixed scope of
            of predefined attributes.  I keep this out of the runtime.Token
            object to avoid a runtime space burden.
        </member>
        <member name="F:Antlr3.Tool.AttributeScope._derivedFromToken">
            This scope is associated with which input token (for error handling)? 
        </member>
        <member name="F:Antlr3.Tool.AttributeScope._name">
            The scope name 
        </member>
        <member name="F:Antlr3.Tool.AttributeScope._isDynamicGlobalScope">
            Not a rule scope, but visible to all rules "scope symbols { ...}" 
        </member>
        <member name="F:Antlr3.Tool.AttributeScope._isDynamicRuleScope">
            Visible to all rules, but defined in rule "scope { int i; }" 
        </member>
        <member name="F:Antlr3.Tool.AttributeScope._attributes">
            The list of Attribute objects 
        </member>
        <member name="M:Antlr3.Tool.AttributeScope.AddAttributes(System.String,System.Int32)">
            From a chunk of text holding the definitions of the attributes,
              pull them apart and create an Attribute for each one.  Add to
              the list of attributes for this scope.  Pass in the character
              that terminates a definition such as ',' or ';'.  For example,
            
              scope symbols {
              	int n;
              	List names;
              }
            
              would pass in definitions equal to the text in between {...} and
              separator=';'.  It results in two Attribute objects.
        </member>
        <member name="M:Antlr3.Tool.AttributeScope.DefineNamedAction(Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST)">
            Given @scope::name {action} define it for this attribute scope. Later,
            the code generator will ask for the actions table.
        </member>
        <member name="M:Antlr3.Tool.AttributeScope.Intersection(Antlr3.Tool.AttributeScope)">
            Return the set of keys that collide from
            this and other.
        </member>
        <member name="T:Antlr3.Tool.BuildDependencyGenerator">
            Given a grammar file, show the dependencies on .tokens etc...
              Using ST, emit a simple "make compatible" list of dependencies.
              For example, combined grammar T.g (no token import) generates:
            
            		TParser.java : T.g
             		T.tokens : T.g
             		T__g : T.g
            
              For tree grammar TP with import of T.tokens:
            
             		TP.g : T.tokens
             		TP.java : TP.g
            
              If "-lib libdir" is used on command-line with -depend, then include the
              path like
            
             		TP.g : libdir/T.tokens
            
              Pay attention to -o as well:
            
             		outputdir/TParser.java : T.g
            
              So this output shows what the grammar depends on *and* what it generates.
            
              Operate on one grammar file at a time.  If given a list of .g on the
              command-line with -depend, just emit the dependencies.  The grammars
              may depend on each other, but the order doesn't matter.  Build tools,
              reading in this output, will know how to organize it.
            
              This is a wee bit slow probably because the code generator has to load
              all of its template files in order to figure out the file extension
              for the generated recognizer.
            
              This code was obvious until I removed redundant "./" on front of files
              and had to escape spaces in filenames :(
        </member>
        <member name="M:Antlr3.Tool.BuildDependencyGenerator.GetGeneratedFileList">
            From T.g return a list of File objects that
            name files ANTLR will emit from T.g.
        </member>
        <member name="M:Antlr3.Tool.BuildDependencyGenerator.GetDependenciesFileList">
            Return a list of File objects that name files ANTLR will read
            to process T.g; This can be .tokens files if the grammar uses the tokenVocab option
            as well as any imported grammar files.
        </member>
        <member name="M:Antlr3.Tool.BuildDependencyGenerator.GetNonImportDependenciesFileList">
             Return a list of File objects that name files ANTLR will read
             to process T.g; This can only be .tokens files and only
             if they use the tokenVocab option.
            
             @return List of dependencies other than imported grammars
        </member>
        <member name="T:Antlr3.Tool.CompositeGrammar">
            A tree of component (delegate) grammars.
            
              Rules defined in delegates are "inherited" like multi-inheritance
              so you can override them.  All token types must be consistent across
              rules from all delegate grammars, so they must be stored here in one
              central place.
            
              We have to start out assuming a composite grammar situation as we can't
              look into the grammar files a priori to see if there is a delegate
              statement.  Because of this, and to avoid duplicating token type tracking
              in each grammar, even single noncomposite grammars use one of these objects
              to track token types.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.refClosureBusy">
            Used during getRuleReferenceClosure to detect computation cycles 
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.stateCounter">
            Used to assign state numbers; all grammars in composite share common
            NFA space.  This NFA tracks state numbers number to state mapping.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.numberToStateList">
            The NFA states in the NFA built from rules across grammars in composite.
            Maps state number to NFAState object.
            This is a Vector instead of a List because I need to be able to grow
            this properly.  After talking to Josh Bloch, Collections guy at Sun,
            I decided this was easiest solution.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.maxTokenType">
            Token names and literal tokens like "void" are uniquely indexed.
            with -1 implying EOF.  Characters are different; they go from
            -1 (EOF) to \uFFFE.  For example, 0 could be a binary byte you
            want to lexer.  Labels of DFA/NFA transitions can be both tokens
            and characters.  I use negative numbers for bookkeeping labels
            like EPSILON. Char/String literals and token types overlap in the same
            space, however.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.tokenIDToTypeMap">
            Map token like ID (but not literals like "while") to its token type 
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.stringLiteralToTypeMap">
            Map token literals like "while" to its token type.  It may be that
            WHILE="while"=35, in which case both tokenIDToTypeMap and this
            field will have entries both mapped to 35.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.typeToStringLiteralList">
            Reverse index for stringLiteralToTypeMap 
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.typeToTokenList">
            Map a token type to its token name.
            Must subtract MIN_TOKEN_TYPE from index.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.lexerRules">
            If combined or lexer grammar, track the rules.
            	Track lexer rules so we can warn about undefined tokens.
             This is combined set of lexer rules from all lexer grammars
             seen in all imports.
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.ruleIndex">
            Rules are uniquely labeled from 1..n among all grammars 
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammar.ruleIndexToRuleList">
            Map a rule index to its name; use a Vector on purpose as new
            collections stuff won't let me setSize and make it grow.  :(
            I need a specific guaranteed index, which the Collections stuff
            won't let me have.
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.AddGrammar(Antlr3.Tool.Grammar,Antlr3.Tool.Grammar)">
            Add delegate grammar as child of delegator 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.GetDelegator(Antlr3.Tool.Grammar)">
            Get parent of this grammar 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.GetDelegates(Antlr3.Tool.Grammar)">
            Get list of all delegates from all grammars in the delegate subtree of g.
            The grammars are in delegation tree preorder.  Don't include g itself
            in list as it is not a delegate of itself.
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.GetIndirectDelegates(Antlr3.Tool.Grammar)">
            Get delegates below direct delegates of g 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.GetDelegators(Antlr3.Tool.Grammar)">
            Return list of delegate grammars from root down to g.
            Order is root, ..., g.parent.  (g not included).
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.GetDelegatedRules(Antlr3.Tool.Grammar)">
            Get set of rules for grammar g that need to have manual delegation
              methods.  This is the list of rules collected from all direct/indirect
              delegates minus rules overridden in grammar g.
            
              This returns null except for the delegate root because it is the only
              one that has to have a complete grammar rule interface.  The delegates
              should not be instantiated directly for use as parsers (you can create
              them to pass to the root parser's ctor as arguments).
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammar.GetAllImportedRules(Antlr3.Tool.Grammar)">
            Get all rule definitions from all direct/indirect delegate grammars
            of g.
        </member>
        <member name="T:Antlr3.Tool.CompositeGrammarTree">
            A tree of grammars 
        </member>
        <member name="F:Antlr3.Tool.CompositeGrammarTree.parent">
            Who is the parent node of this node; if null, implies node is root 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammarTree.GetRule(System.String)">
            Find a rule by looking in current grammar then down towards the
            delegate grammars.
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammarTree.GetOption(System.String)">
            Find an option by looking up towards the root grammar rather than down 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammarTree.GetPostOrderedGrammarList">
            Return a postorder list of grammars; root is last in list 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammarTree.GetPostOrderedGrammarListCore(System.Collections.Generic.IList{Antlr3.Tool.Grammar})">
            work for getPostOrderedGrammarList 
        </member>
        <member name="M:Antlr3.Tool.CompositeGrammarTree.GetPreOrderedGrammarList">
            Return a preorder list of grammars; root is first in list 
        </member>
        <member name="T:Antlr3.Tool.DOTGenerator">
            The DOT (part of graphviz) generation aspect. 
        </member>
        <member name="F:Antlr3.Tool.DOTGenerator._stlib">
            <summary>Library of output templates; use &lt;attrname&gt; format</summary> 
        </member>
        <member name="F:Antlr3.Tool.DOTGenerator.markedStates">
            To prevent infinite recursion when walking state machines, record
            which states we've visited.  Make a new set every time you start
            walking in case you reuse this object.
        </member>
        <member name="M:Antlr3.Tool.DOTGenerator.#ctor(Antlr3.Tool.Grammar)">
            This aspect is associated with a grammar 
        </member>
        <member name="M:Antlr3.Tool.DOTGenerator.GenerateGraph(Antlr3.Analysis.State)">
            Return a String containing a DOT description that, when displayed,
            will show the incoming state machine visually.  All nodes reachable
            from startState will be included.
        </member>
        <member name="M:Antlr3.Tool.DOTGenerator.WalkCreatingDFADOT(Antlr4.StringTemplate.Template,Antlr3.Analysis.DFAState)">
            Do a depth-first walk of the state machine graph and
            fill a DOT description template.  Keep filling the
            states and edges attributes.
        </member>
        <member name="M:Antlr3.Tool.DOTGenerator.WalkRuleNFACreatingDOT(Antlr4.StringTemplate.Template,Antlr3.Analysis.State)">
            Do a depth-first walk of the state machine graph and
            fill a DOT description template.  Keep filling the
            states and edges attributes.  We know this is an NFA
            for a rule so don't traverse edges to other rules and
            don't go past rule end state.
        </member>
        <member name="M:Antlr3.Tool.DOTGenerator.GetEdgeLabel(Antlr3.Analysis.Transition)">
            Fix edge strings so they print out in DOT properly;
            generate any gated predicates on edge too.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.ErrorsForcingNoAnalysis">
            Do not do perform analysis if one of these happens 
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.ErrorsForcingNoCodegen">
            Do not do code gen if one of these happens 
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.emitSingleError">
            Only one error can be emitted for any entry in this table.
            Map from string to a set where the key is a method name like danglingState.
            The set is whatever that method accepts or derives like a DFA.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.locale">
            Messages should be sensitive to the locale. 
        </member>
        <member name="F:Antlr3.Tool.ErrorManager._listener">
            Each thread might need it's own error listener; e.g., a GUI with
            multiple window frames holding multiple grammars.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager._errorState">
            Track the number of errors regardless of the listener but track
            per thread.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager._tool">
            Each thread has its own ptr to a Tool object, which knows how
            to panic, for example.  In a GUI, the thread might just throw an Error
            to exit rather than the suicide System.exit.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.messages">
            The group of templates that represent all possible ANTLR errors. 
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.format">
            The group of templates that represent the current message format. 
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.idToMessageTemplateName">
            From a msgID how can I get the name of the template that describes
            the error or warning?
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.initSTListener">
            Handle all ST error listeners here (code gen, Grammar, and this class
            use templates.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.blankSTListener">
            During verification of the messages group file, don't gen errors.
            I'll handle them here.  This is used only after file has loaded ok
            and only for the messages STG.
        </member>
        <member name="F:Antlr3.Tool.ErrorManager.theDefaultSTListener">
            Errors during initialization related to ST must all go to System.err.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.SetLocale(System.Globalization.CultureInfo)">
            We really only need a single locale for entire running ANTLR code
            in a single VM.  Only pay attention to the language, not the country
            so that French Canadians and French Frenchies all get the same
            template file, fr.stg.  Just easier this way.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.SetFormat(System.String)">
            The format gets reset either from the Tool if the user supplied a command line option to that effect
            Otherwise we just use the default "antlr".
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.SetErrorListener(Antlr3.Tool.IANTLRErrorListener)">
            Encodes the error handling found in setLocale, but does not trigger
                     *  panics, which would make GUI tools die if ANTLR's installation was
                     *  a bit screwy.  Duplicated code...ick.
                    public static Locale getLocaleForValidMessages(Locale locale) {
                        ErrorManager.locale = locale;
                        String language = locale.getLanguage();
                        String fileName = "org/antlr/tool/templates/messages/"+language+".stg";
                        ClassLoader cl = Thread.currentThread().getContextClassLoader();
                        InputStream is = cl.getResourceAsStream(fileName);
                        if ( is==null &amp;&amp; language.equals(Locale.US.getLanguage()) ) {
                            return null;
                        }
                        else if ( is==null ) {
                            return getLocaleForValidMessages(Locale.US); // recurse on this rule, trying the US locale
                        }
            
                        boolean messagesOK = verifyMessages();
                        if ( !messagesOK &amp;&amp; language.equals(Locale.US.getLanguage()) ) {
                            return null;
                        }
                        else if ( !messagesOK ) {
                            return getLocaleForValidMessages(Locale.US); // try US to see if that will work
                        }
                        return true;
                    }
            In general, you'll want all errors to go to a single spot.
            However, in a GUI, you might have two frames up with two
            different grammars.  Two threads might launch to process the
            grammars--you would want errors to go to different objects
            depending on the thread.  I store a single listener per
            thread.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.GetMessage(System.Int32)">
            Given a message ID, return a StringTemplate that somebody can fill
            with data.  We need to convert the int ID to the name of a template
            in the messages ST group.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.GetLocationFormat">
            Return a StringTemplate that refers to the current format used for
            emitting messages.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.GetLastNonErrorManagerCodeLocation(System.Exception)">
            Return first non ErrorManager code location for generating messages 
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.VerifyMessages">
            Use reflection to find list of MSG_ fields and then verify a
            template exists for each one from the locale's group.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.VerifyFormat">
            Verify the message format template group 
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.RawError(System.String)">
            If there are errors during ErrorManager init, we have no choice
            but to go to System.err.
        </member>
        <member name="M:Antlr3.Tool.ErrorManager.Panic">
            I *think* this will allow Tool subclasses to exit gracefully
            for GUIs etc...
        </member>
        <member name="T:Antlr3.Tool.FASerializer">
            An aspect of FA (finite automata) that knows how to dump them to serialized
            strings.
        </member>
        <member name="F:Antlr3.Tool.FASerializer.markedStates">
            To prevent infinite recursion when walking state machines, record
            which states we've visited.  Make a new set every time you start
            walking in case you reuse this object.  Multiple threads will trash
            this shared variable.  Use a different FASerializer per thread.
        </member>
        <member name="F:Antlr3.Tool.FASerializer.stateCounter">
            Each state we walk will get a new state number for serialization
            purposes.  This is the variable that tracks state numbers.
        </member>
        <member name="F:Antlr3.Tool.FASerializer.stateNumberTranslator">
            Rather than add a new instance variable to NFA and DFA just for
            serializing machines, map old state numbers to new state numbers
            by a State object -> Integer new state number HashMap.
        </member>
        <member name="M:Antlr3.Tool.FASerializer.#ctor(Antlr3.Tool.Grammar)">
            This aspect is associated with a grammar; used to get token names 
        </member>
        <member name="M:Antlr3.Tool.FASerializer.Serialize(Antlr3.Analysis.State,System.Boolean)">
            Return a string representation of a state machine.  Two identical
            NFAs or DFAs will have identical serialized representations.  The
            state numbers inside the state are not used; instead, a new number
            is computed and because the serialization will walk the two
            machines using the same specific algorithm, then the state numbers
            will be identical.  Accept states are distinguished from regular
            states.
        </member>
        <member name="M:Antlr3.Tool.FASerializer.WalkFANormalizingStateNumbers(Antlr3.Analysis.State)">
            In stateNumberTranslator, get a map from State to new, normalized
            state number.  Used by walkSerializingFA to make sure any two
            identical state machines will serialize the same way.
        </member>
        <member name="T:Antlr3.Tool.Grammar">
            Represents a grammar in memory. 
        </member>
        <member name="F:Antlr3.Tool.Grammar.LexerGrammarFileExtension">
            used for generating lexer temp files 
        </member>
        <member name="F:Antlr3.Tool.Grammar.AntlrLiteralEscapedCharValue">
            When converting ANTLR char and string literals, here is the
            value set of escape chars.
        </member>
        <member name="F:Antlr3.Tool.Grammar.AntlrLiteralCharValueEscape">
            Given a char, we need to be able to show as an ANTLR literal.
        </member>
        <member name="F:Antlr3.Tool.Grammar.validDelegations">
            Set of valid imports.  E.g., can only import a tree parser into
            another tree parser.  Maps delegate to set of delegator grammar types.
            validDelegations.get(LEXER) gives list of the kinds of delegators
            that can import lexers.
        </member>
        <member name="F:Antlr3.Tool.Grammar.tokenBuffer">
            This is the buffer of *all* tokens found in the grammar file
            including whitespace tokens etc...  I use this to extract
            lexer rules from combined grammars.
        </member>
        <member name="F:Antlr3.Tool.Grammar.LabelElementPair.actionReferencesLabel">
            Has an action referenced the label?  Set by ActionAnalysis.g
            Currently only set for rule labels.
        </member>
        <member name="F:Antlr3.Tool.Grammar.name">
            What name did the user provide for this grammar? 
        </member>
        <member name="F:Antlr3.Tool.Grammar.type">
            What type of grammar is this: lexer, parser, tree walker 
        </member>
        <member name="F:Antlr3.Tool.Grammar.options">
            A list of options specified at the grammar level such as language=Java.
            The value can be an AST for complicated values such as character sets.
            There may be code generator specific options in here.  I do no
            interpretation of the key/value pairs...they are simply available for
            who wants them.
        </member>
        <member name="F:Antlr3.Tool.Grammar.defaultBlockOptions">
            What are the default options for a subrule? 
        </member>
        <member name="F:Antlr3.Tool.Grammar.legalTokenOptions">
            Legal options for terminal refs like ID&lt;node=MyVarNode&gt; 
        </member>
        <member name="F:Antlr3.Tool.Grammar.global_k">
            Is there a global fixed lookahead set for this grammar?
            If 0, nothing specified.  -1 implies we have not looked at
            the options table yet to set k.
        </member>
        <member name="F:Antlr3.Tool.Grammar.actions">
            Map a scope to a map of name:action pairs.
            Map&lt;String, Map&lt;String,GrammarAST&gt;&gt;
            The code generator will use this to fill holes in the output files.
            I track the AST node for the action in case I need the line number
            for errors.
        </member>
        <member name="F:Antlr3.Tool.Grammar.nfa">
            The NFA that represents the grammar with edges labelled with tokens
            or epsilon.  It is more suitable to analysis than an AST representation.
        </member>
        <member name="F:Antlr3.Tool.Grammar.composite">
            If this grammar is part of a larger composite grammar via delegate
            statement, then this points at the composite.  The composite holds
            a global list of rules, token types, decision numbers, etc...
        </member>
        <member name="F:Antlr3.Tool.Grammar.compositeTreeNode">
            A pointer back into grammar tree.  Needed so we can add delegates. 
        </member>
        <member name="F:Antlr3.Tool.Grammar.label">
            If this is a delegate of another grammar, this is the label used
            as an instance var by that grammar to point at this grammar. null
            if no label was specified in the delegate statement.
        </member>
        <member name="F:Antlr3.Tool.Grammar.charVocabulary">
            TODO: hook this to the charVocabulary option 
        </member>
        <member name="F:Antlr3.Tool.Grammar.lineColumnToLookaheadDFAMap">
            For ANTLRWorks, we want to be able to map a line:col to a specific
            decision DFA so it can display DFA.
        </member>
        <member name="F:Antlr3.Tool.Grammar.ruleRefs">
            The unique set of all rule references in any rule; set of tree node
            objects so two refs to same rule can exist but at different line/position.
        </member>
        <member name="F:Antlr3.Tool.Grammar.tokenIDRefs">
            The unique set of all token ID references in any rule 
        </member>
        <member name="F:Antlr3.Tool.Grammar.decisionCount">
            Be able to assign a number to every decision in grammar;
            decisions in 1..n
        </member>
        <member name="F:Antlr3.Tool.Grammar.leftRecursiveRules">
            A list of all rules that are in any left-recursive cycle.  There
            could be multiple cycles, but this is a flat list of all problematic
            rules. This is stuff we couldn't refactor to precedence rule.
        </member>
        <member name="F:Antlr3.Tool.Grammar.externalAnalysisAbort">
            An external tool requests that DFA analysis abort prematurely.  Stops
            at DFA granularity, which are limited to a DFA size and time computation
            as failsafe.
        </member>
        <member name="F:Antlr3.Tool.Grammar.nameToSynpredASTMap">
            When we read in a grammar, we track the list of syntactic predicates
            and build faux rules for them later.  See my blog entry Dec 2, 2005:
            http://www.antlr.org/blog/antlr3/lookahead.tml
            This maps the name (we make up) for a pred to the AST grammar fragment.
        </member>
        <member name="F:Antlr3.Tool.Grammar.precRuleInitCodeBlocks">
            Each left-recursive precedence rule must define precedence array
              for binary operators like:
            
              	static int[] e_prec = new int[tokenNames.length];
              	static {
              		e_prec[75] = 1;
              	}
              Track and we push into parser later; this is computed
              early when we look for prec rules.
        </member>
        <member name="F:Antlr3.Tool.Grammar.atLeastOneRuleMemoizes">
            At least one rule has memoize=true 
        </member>
        <member name="F:Antlr3.Tool.Grammar.atLeastOneBacktrackOption">
            At least one backtrack=true in rule or decision or grammar. 
        </member>
        <member name="F:Antlr3.Tool.Grammar.implicitLexer">
            Was this created from a COMBINED grammar? 
        </member>
        <member name="F:Antlr3.Tool.Grammar.nameToRuleMap">
            Map a rule to it's Rule object 
        </member>
        <member name="F:Antlr3.Tool.Grammar.overriddenRules">
            If this rule is a delegate, some rules might be overridden; don't
            want to gen code for them.
        </member>
        <member name="F:Antlr3.Tool.Grammar.delegatedRuleReferences">
            The list of all rules referenced in this grammar, not defined here,
            and defined in a delegate grammar.  Not all of these will be generated
            in the recognizer for this file; only those that are affected by rule
            definitions in this grammar.  I am not sure the Java target will need
            this but I'm leaving in case other targets need it.
            see NameSpaceChecker.lookForReferencesToUndefinedSymbols()
        </member>
        <member name="F:Antlr3.Tool.Grammar.lexerRuleNamesInCombined">
            The ANTLRParser tracks lexer rules when reading combined grammars
            so we can build the Tokens rule.
        </member>
        <member name="F:Antlr3.Tool.Grammar.scopes">
            Track the scopes defined outside of rules and the scopes associated
            with all rules (even if empty).
        </member>
        <member name="F:Antlr3.Tool.Grammar.grammarTree">
            An AST that records entire input grammar with all rules.  A simple
             grammar with one rule, "grammar t; a : A | B ;", looks like:
            ( grammar t ( rule a ( BLOCK ( ALT A ) ( ALT B ) ) &lt;end-of-rule&gt; ) )
        </member>
        <member name="F:Antlr3.Tool.Grammar.indexToDecision">
            Each subrule/rule is a decision point and we must track them so we
            can go back later and build DFA predictors for them.  This includes
            all the rules, subrules, optional blocks, ()+, ()* etc...
        </member>
        <member name="F:Antlr3.Tool.Grammar.generator">
            If non-null, this is the code generator we will use to generate
            recognizers in the target language.
        </member>
        <member name="F:Antlr3.Tool.Grammar._lexerGrammarTemplate">
            For merged lexer/parsers, we must construct a separate lexer spec.
            This is the template for lexer; put the literals first then the
            regular rules.  We don't need to specify a token vocab import as
            I make the new grammar import from the old all in memory; don't want
            to force it to read from the disk.  Lexer grammar will have same
            name as original grammar but will be in different filename.  Foo.g
            with combined grammar will have FooParser.java generated and
            Foo__.g with again Foo inside.  It will however generate FooLexer.java
            as it's a lexer grammar.  A bit odd, but autogenerated.  Can tweak
            later if we want.
        </member>
        <member name="F:Antlr3.Tool.Grammar.fileName">
            What file name holds this grammar? 
        </member>
        <member name="F:Antlr3.Tool.Grammar.DFACreationWallClockTimeInMS">
            How long in ms did it take to build DFAs for this grammar?
            If this grammar is a combined grammar, it only records time for
            the parser grammar component.  This only records the time to
            do the LL(*) work; NFA->DFA conversion.
        </member>
        <member name="F:Antlr3.Tool.Grammar.blocksWithSynPreds">
            Track decisions with syn preds specified for reporting.
            This is the a set of BLOCK type AST nodes.
        </member>
        <member name="F:Antlr3.Tool.Grammar.decisionsWhoseDFAsUsesSynPreds">
            Track decisions that actually use the syn preds in the DFA.
            Computed during NFA to DFA conversion.
        </member>
        <member name="F:Antlr3.Tool.Grammar.synPredNamesUsedInDFA">
            Track names of preds so we can avoid generating preds that aren't used
            Computed during NFA to DFA conversion.  Just walk accept states
            and look for synpreds because that is the only state target whose
            incident edges can have synpreds.  Same is try for
            decisionsWhoseDFAsUsesSynPreds.
        </member>
        <member name="F:Antlr3.Tool.Grammar.blocksWithSemPreds">
            Track decisions with syn preds specified for reporting.
            This is the a set of BLOCK type AST nodes.
        </member>
        <member name="F:Antlr3.Tool.Grammar.decisionsWhoseDFAsUsesSemPreds">
            Track decisions that actually use the syn preds in the DFA. 
        </member>
        <member name="F:Antlr3.Tool.Grammar.builtFromString">
            We need a way to detect when a lexer grammar is autogenerated from
            another grammar or we are just sending in a string representing a
            grammar.  We don't want to generate a .tokens file, for example,
            in such cases.
        </member>
        <member name="F:Antlr3.Tool.Grammar.sanity">
            Factored out the sanity checking code; delegate to it. 
        </member>
        <member name="F:Antlr3.Tool.Grammar.target">
            Useful for asking questions about target during analysis 
        </member>
        <member name="M:Antlr3.Tool.Grammar.#ctor(Antlr3.AntlrTool,System.String,Antlr3.Tool.CompositeGrammar)">
            Create a grammar from file name.  
        </member>
        <member name="M:Antlr3.Tool.Grammar.#ctor(Antlr3.AntlrTool)">
            Useful for when you are sure that you are not part of a composite
            already.  Used in Interp/RandomPhrase and testing.
        </member>
        <member name="M:Antlr3.Tool.Grammar.#ctor(System.String)">
            Used for testing; only useful on noncomposite grammars.
        </member>
        <member name="M:Antlr3.Tool.Grammar.#ctor(Antlr3.AntlrTool,System.String)">
            Used for testing and Interp/RandomPhrase.  Only useful on
            noncomposite grammars.
        </member>
        <member name="P:Antlr3.Tool.Grammar.AllCharValues">
            If there is a char vocabulary, use it; else return min to max char
            as defined by the target.  If no target, use max unicode char value.
        </member>
        <member name="P:Antlr3.Tool.Grammar.Delegator">
            Who's my direct parent grammar? 
        </member>
        <member name="P:Antlr3.Tool.Grammar.MaxCharValue">
            What is the max char value possible for this grammar's target?  Use
            unicode max if no target defined.
        </member>
        <member name="P:Antlr3.Tool.Grammar.MaxTokenType">
            How many token types have been allocated so far? 
        </member>
        <member name="P:Antlr3.Tool.Grammar.StringLiterals">
            Get the list of ANTLR String literals 
        </member>
        <member name="P:Antlr3.Tool.Grammar.TokenIDs">
            Get the list of tokens that are IDs like BLOCK and LPAREN 
        </member>
        <member name="P:Antlr3.Tool.Grammar.TokenTypes">
            Return a set of all possible token or char types for this grammar 
        </member>
        <member name="M:Antlr3.Tool.Grammar.CheckNameSpaceAndActions">
            ANALYZE ACTIONS, LOOKING FOR LABEL AND ATTR REFS, sanity check 
        </member>
        <member name="M:Antlr3.Tool.Grammar.ValidImport(Antlr3.Tool.Grammar)">
            Many imports are illegal such as lexer into a tree grammar 
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetLexerGrammar">
            If the grammar is a combined grammar, return the text of the implicit
            lexer grammar.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetRecognizerName">
            Get the name of the generated recognizer; may or may not be same
            as grammar name.
            Recognizer is TParser and TLexer from T if combined, else
            just use T regardless of grammar type.
        </member>
        <member name="M:Antlr3.Tool.Grammar.AddArtificialMatchTokensRule(Antlr3.Tool.GrammarAST,System.Collections.Generic.IList{System.String},System.Collections.Generic.IList{System.String},System.Boolean)">
            Parse a rule we add artificially that is a list of the other lexer
              rules like this: "Tokens : ID | INT | SEMI ;"  nextToken() will invoke
              this to set the current token.  Add char literals before
              the rule references.
            
              If in filter mode, we want every alt to backtrack and we need to
              do k=1 to force the "first token def wins" rule.  Otherwise, the
              longest-match rule comes into play with LL(*).
            
              The ANTLRParser antlr.g file now invokes this when parsing a lexer
              grammar, which I think is proper even though it peeks at the info
              that later phases will (re)compute.  It gets a list of lexer rules
              and builds a string representing the rule; then it creates a parser
              and adds the resulting tree to the grammar's tree.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetArtificialRulesForSyntacticPredicates(System.Collections.Generic.IEnumerable{System.Collections.Generic.KeyValuePair{System.String,Antlr3.Tool.GrammarAST}})">
            for any syntactic predicates, we need to define rules for them; they will get
            defined automatically like any other rule. :)
        </member>
        <member name="M:Antlr3.Tool.Grammar.CreateRuleStartAndStopNFAStates">
            Define all the rule begin/end NFAStates to solve forward reference
            issues.  Critical for composite grammars too.
            This is normally called on all root/delegates manually and then
            buildNFA() is called afterwards because the NFA construction needs
            to see rule start/stop states from potentially every grammar. Has
            to be have these created a priori.  Testing routines will often
            just call buildNFA(), which forces a call to this method if not
            done already. Works ONLY for single noncomposite grammars.
        </member>
        <member name="M:Antlr3.Tool.Grammar.CreateLookaheadDFAs">
            For each decision in this grammar, compute a single DFA using the
              NFA states associated with the decision.  The DFA construction
              determines whether or not the alternatives in the decision are
              separable using a regular lookahead language.
            
              Store the lookahead DFAs in the AST created from the user's grammar
              so the code generator or whoever can easily access it.
            
              This is a separate method because you might want to create a
              Grammar without doing the expensive analysis.
        </member>
        <member name="M:Antlr3.Tool.Grammar.ExternallyAbortNFAToDFAConversion">
            Terminate DFA creation (grammar analysis).
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetNewTokenType">
            Return a new unique integer in the token type space 
        </member>
        <member name="M:Antlr3.Tool.Grammar.DefineToken(System.String,System.Int32)">
            Define a token at a particular token type value.  Blast an
            old value with a new one.  This is called normal grammar processsing
            and during import vocab operations to set tokens with specific values.
        </member>
        <member name="M:Antlr3.Tool.Grammar.DefineRule(Antlr.Runtime.IToken,System.String,System.Collections.Generic.IDictionary{System.String,System.Object},Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST,System.Int32)">
            Define a new rule.  A new rule index is created by incrementing
            ruleIndex.
        </member>
        <member name="M:Antlr3.Tool.Grammar.DefineSyntacticPredicate(Antlr3.Tool.GrammarAST,System.String)">
            Define a new predicate and get back its name for use in building
            a semantic predicate reference to the syn pred.
        </member>
        <member name="M:Antlr3.Tool.Grammar.DefineNamedAction(Antlr3.Tool.GrammarAST,System.String,Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST)">
            Given @scope::name {action} define it for this grammar.  Later,
            the code generator will ask for the actions table.  For composite
            grammars, make sure header action propogates down to all delegates.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetDefaultActionScope(Antlr3.Tool.GrammarType)">
            Given a grammar type, what should be the default action scope?
            If I say @members in a COMBINED grammar, for example, the
            default scope should be "parser".
        </member>
        <member name="M:Antlr3.Tool.Grammar.DefineLexerRuleForAliasedStringLiteral(System.String,System.String,System.Int32)">
            If someone does PLUS='+' in the parser, must make sure we get
            "PLUS : '+' ;" in lexer not "T73 : '+';"
        </member>
        <member name="M:Antlr3.Tool.Grammar.GenerateMethodForRule(System.String)">
            Should codegen.g gen rule for ruleName?
            	If synpred, only gen if used in a DFA.
             If regular rule, only gen if not overridden in delegator
             Always gen Tokens rule though.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetGlobalScope(System.String)">
            Get a global scope 
        </member>
        <member name="M:Antlr3.Tool.Grammar.DefineLabel(Antlr3.Tool.Rule,Antlr.Runtime.IToken,Antlr3.Tool.GrammarAST,Antlr3.Tool.LabelType)">
            Define a label defined in a rule r; check the validity then ask the
            Rule object to actually define it.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetLabels(System.Collections.Generic.HashSet{Antlr3.Tool.GrammarAST},Antlr3.Tool.LabelType)">
            Given a set of all rewrite elements on right of ->, filter for
            label types such as Grammar.TOKEN_LABEL, Grammar.TOKEN_LIST_LABEL, ...
            Return a displayable token type name computed from the GrammarAST.
        </member>
        <member name="M:Antlr3.Tool.Grammar.ExamineAllExecutableActions">
            Before generating code, we examine all actions that can have
            $x.y and $y stuff in them because some code generation depends on
            Rule.referencedPredefinedRuleAttributes.  I need to remove unused
            rule labels for example.
        </member>
        <member name="M:Antlr3.Tool.Grammar.CheckAllRulesForUselessLabels">
            Remove all labels on rule refs whose target rules have no return value.
            Do this for all rules in grammar.
        </member>
        <member name="M:Antlr3.Tool.Grammar.RemoveUselessLabels(System.Collections.Generic.IDictionary{System.String,Antlr3.Tool.Grammar.LabelElementPair})">
            A label on a rule is useless if the rule has no return value, no
            tree or template output, and it is not referenced in an action.
        </member>
        <member name="M:Antlr3.Tool.Grammar.AltReferencesRule(System.String,Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST,System.Int32)">
            Track a rule reference within an outermost alt of a rule.  Used
              at the moment to decide if $ruleref refers to a unique rule ref in
              the alt.  Rewrite rules force tracking of all rule AST results.
            
              This data is also used to verify that all rules have been defined.
        </member>
        <member name="M:Antlr3.Tool.Grammar.AltReferencesTokenID(System.String,Antlr3.Tool.GrammarAST,System.Int32)">
            Track a token reference within an outermost alt of a rule.  Used
              to decide if $tokenref refers to a unique token ref in
              the alt. Does not track literals!
            
              Rewrite rules force tracking of all tokens.
        </member>
        <member name="M:Antlr3.Tool.Grammar.ReferenceRuleLabelPredefinedAttribute(System.String)">
            To yield smaller, more readable code, track which rules have their
            predefined attributes accessed.  If the rule has no user-defined
            return values, then don't generate the return value scope classes
            etc...  Make the rule have void return value.  Don't track for lexer
            rules.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetLeftRecursiveRules">
            Return a list of left-recursive rules; no analysis can be done
            successfully on these.  Useful to skip these rules then and also
            for ANTLRWorks to highlight them.
        </member>
        <member name="M:Antlr3.Tool.Grammar.IsEmptyRule(Antlr3.Tool.GrammarAST)">
            Rules like "a : ;" and "a : {...} ;" should not generate
            try/catch blocks for RecognitionException.  To detect this
            it's probably ok to just look for any reference to an atom
            that can match some input.  W/o that, the rule is unlikey to have
            any else.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetTokenTypesWithoutID">
            Return an ordered integer list of token types that have no
            corresponding token ID like INT or KEYWORD_BEGIN; for stuff
            like 'begin'.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetTokenDisplayNames">
            Get a list of all token IDs and literals that have an associated
            token type.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetCharValueFromGrammarCharLiteral(System.String)">
            Given a literal like (the 3 char sequence with single quotes) 'a',
              return the int value of 'a'. Convert escape sequences here also.
              ANTLR's antlr.g parser does not convert escape sequences.
            
              11/26/2005: I changed literals to always be '...' even for strings.
              This routine still works though.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetUnescapedStringFromGrammarStringLiteral(System.String)">
            ANTLR does not convert escape sequences during the parse phase because
              it could not know how to print String/char literals back out when
              printing grammars etc...  Someone in China might use the real unicode
              char in a literal as it will display on their screen; when printing
              back out, I could not know whether to display or use a unicode escape.
            
              This routine converts a string literal with possible escape sequences
              into a pure string of 16-bit char values.  Escapes and unicode \u0000
              specs are converted to pure chars.  return in a buffer; people may
              want to walk/manipulate further.
            
              The NFA construction routine must know the actual char values.
        </member>
        <member name="M:Antlr3.Tool.Grammar.ImportTokenVocabulary(Antlr3.Tool.Grammar)">
            Pull your token definitions from an existing grammar in memory.
              You must use Grammar() ctor then this method then setGrammarContent()
              to make this work.  This was useful primarily for testing and
              interpreting grammars until I added import grammar functionality.
              When you import a grammar you implicitly import its vocabulary as well
              and keep the same token type values.
            
              Returns the max token type found.
        </member>
        <member name="M:Antlr3.Tool.Grammar.ImportGrammar(Antlr.Runtime.IToken,System.String)">
            Import the rules/tokens of a delegate grammar. All delegate grammars are
              read during the ctor of first Grammar created.
            
              Do not create NFA here because NFA construction needs to hook up with
              overridden rules in delegation root grammar.
        </member>
        <member name="M:Antlr3.Tool.Grammar.AddDelegateGrammar(Antlr3.Tool.Grammar)">
            add new delegate to composite tree 
        </member>
        <member name="M:Antlr3.Tool.Grammar.ImportTokenVocabulary(Antlr3.Tool.GrammarAST,System.String)">
            Load a vocab file &lt;vocabName&gt;.tokens and return max token type found. 
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetTokenDisplayName(System.Int32)">
            Given a token type, get a meaningful name for it such as the ID
            or string literal.  If this is a lexer and the ttype is in the
            char vocabulary, compute an ANTLR-valid (possibly escaped) char literal.
        </member>
        <member name="M:Antlr3.Tool.Grammar.SetOption(System.String,System.Object,Antlr.Runtime.IToken)">
            Save the option key/value pair and process it; return the key
            or null if invalid option.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetDelegatedRules">
            Get the set of Rules that need to have manual delegations
              like "void rule() { importedGrammar.rule(); }"
            
              If this grammar is master, get list of all rule definitions from all
              delegate grammars.  Only master has complete interface from combined
              grammars...we will generated delegates as helper objects.
            
              Composite grammars that are not the root/master do not have complete
              interfaces.  It is not my intention that people use subcomposites.
              Only the outermost grammar should be used from outside code.  The
              other grammar components are specifically generated to work only
              with the master/root. 
            
              delegatedRules = imported - overridden
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetAllImportedRules">
            Get set of all rules imported from all delegate grammars even if
            indirectly delegated.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetDelegates">
            Get list of all delegates from all grammars directly or indirectly
            imported into this grammar.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetIndirectDelegates">
            Get delegates below direct delegates 
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetDelegators">
            Get list of all delegators.  This amounts to the grammars on the path
            to the root of the delegation tree.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetLookaheadDFAColumnsForLineInFile(System.Int32)">
            returns a list of column numbers for all decisions
              on a particular line so ANTLRWorks choose the decision
              depending on the location of the cursor (otherwise,
              ANTLRWorks has to give the *exact* location which
              is not easy from the user point of view).
            
              This is not particularly fast as it walks entire line:col->DFA map
              looking for a prefix of "line:".
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetLookaheadDFAFromPositionInFile(System.Int32,System.Int32)">
            Useful for ANTLRWorks to map position in file to the DFA for display 
        </member>
        <member name="M:Antlr3.Tool.Grammar.SetLookaheadDFA(System.Int32,Antlr3.Analysis.DFA)">
            Set the lookahead DFA for a particular decision.  This means
              that the appropriate AST node must updated to have the new lookahead
              DFA.  This method could be used to properly set the DFAs without
              using the createLookaheadDFAs() method.  You could do this
            
                Grammar g = new Grammar("...");
                g.setLookahead(1, dfa1);
                g.setLookahead(2, dfa2);
                ...
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetANTLRCharLiteralForChar(System.Int32)">
            Return a string representing the escaped char for code c.  E.g., If c
              has value 0x100, you will get "\u0100".  ASCII gets the usual
              char (non-hex) representation.  Control characters are spit out
              as unicode.  While this is specially set up for returning Java strings,
              it can be used by any language target that has the same syntax. :)
            
              11/26/2005: I changed this to use double quotes, consistent with antlr.g
              12/09/2005: I changed so everything is single quotes
        </member>
        <member name="M:Antlr3.Tool.Grammar.Complement(Antlr3.Misc.IIntSet)">
            For lexer grammars, return everything in unicode not in set.
            For parser and tree grammars, return everything in token space
            from MIN_TOKEN_TYPE to last valid token type or char value.
        </member>
        <member name="M:Antlr3.Tool.Grammar.IsValidSet(Antlr3.Grammars.TreeToNFAConverter,Antlr3.Tool.GrammarAST)">
            Given set tree like ( SET A B ), check that A and B
            are both valid sets themselves, else we must tree like a BLOCK
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetSetFromRule(Antlr3.Grammars.TreeToNFAConverter,System.String)">
            Get the set equivalent (if any) of the indicated rule from this
              grammar.  Mostly used in the lexer to do ~T for some fragment rule
              T.  If the rule AST has a SET use that.  If the rule is a single char
              convert it to a set and return.  If rule is not a simple set (w/o actions)
              then return null.
              Rules have AST form:
            
            		^( RULE ID modifier ARG RET SCOPE block EOR )
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetNumberOfAltsForDecisionNFA(Antlr3.Analysis.NFAState)">
            Decisions are linked together with transition(1).  Count how
            many there are.  This is here rather than in NFAState because
            a grammar decides how NFAs are put together to form a decision.
        </member>
        <member name="M:Antlr3.Tool.Grammar.GetNFAStateForAltOfDecision(Antlr3.Analysis.NFAState,System.Int32)">
            Get the ith alternative (1..n) from a decision; return null when
              an invalid alt is requested.  I must count in to find the right
              alternative number.  For (A|B), you get NFA structure (roughly):
            
              o->o-A->o
              |
              o->o-B->o
            
              This routine returns the leftmost state for each alt.  So alt=1, returns
              the upperleft most state in this structure.
        </member>
        <member name="M:Antlr3.Tool.Grammar.ComputeTokenNameFromLiteral(System.Int32,System.String)">
            given a token type and the text of the literal, come up with a
            decent token type label.  For now it's just T&lt;type&gt;.  Actually,
            if there is an aliased name from tokens like PLUS='+', use it.
        </member>
        <member name="T:Antlr3.Tool.GrammarAnalysisAbortedMessage">
            Reports the condition that ANTLR's LL(*) analysis engine terminated
            early.
        </member>
        <member name="T:Antlr3.Tool.GrammarAST">
            Grammars are first converted to ASTs using this class and then are
              converted to NFAs via a tree walker.
            
              The reader may notice that I have made a very non-OO decision in this
              class to track variables for many different kinds of nodes.  It wastes
              space for nodes that don't need the values and OO principles cry out
              for a new class type for each kind of node in my tree.  I am doing this
              on purpose for a variety of reasons.  I don't like using the type
              system for different node types; it yields too many damn class files
              which I hate.  Perhaps if I put them all in one file.  Most importantly
              though I hate all the type casting that would have to go on.  I would
              have all sorts of extra work to do.  Ick.  Anyway, I'm doing all this
              on purpose, not out of ignorance. ;)
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.enclosingRuleName">
            This AST node was created from what token? 
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.lookaheadDFA">
            If this is a decision node, what is the lookahead DFA? 
        </member>
        <member name="F:Antlr3.Tool.GrammarAST._nfaStartState">
            What NFA start state was built from this node? 
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.NFATreeDownState">
            This is used for TREE_BEGIN nodes to point into
            the NFA.  TREE_BEGINs point at left edge of DOWN for LOOK computation
            purposes (Nullable tree child list needs special code gen when matching).
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.followingNFAState">
            Rule ref nodes, token refs, set, and NOT set refs need to track their
            location in the generated NFA so that local FOLLOW sets can be
            computed during code gen for automatic error recovery.
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.setValue">
            If this is a SET node, what are the elements? 
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.blockOptions">
            If this is a BLOCK node, track options here 
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.rewriteRefsShallow">
            If this is a BLOCK node for a rewrite rule, track referenced
            elements here.  Don't track elements in nested subrules.
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.outerAltNum">
            if this is an ACTION node, this is the outermost enclosing
            alt num in rule.  For actions, define.g sets these (used to
            be codegen.g).  We need these set so we can examine actions
            early, before code gen, for refs to rule predefined properties
            and rule labels.  For most part define.g sets outerAltNum, but
            codegen.g does the ones for %foo(a={$ID.text}) type refs as
            the {$ID...} is not seen as an action until code gen pulls apart.
        </member>
        <member name="F:Antlr3.Tool.GrammarAST.code">
            if this is a TOKEN_REF or RULE_REF node, this is the code StringTemplate
            generated for this node.  We need to update it later to add
            a label if someone does $tokenref or $ruleref in an action.
        </member>
        <member name="M:Antlr3.Tool.GrammarAST.SetBlockOption(Antlr3.Tool.Grammar,System.String,System.Object)">
            Save the option key/value pair and process it; return the key
            or null if invalid option.
        </member>
        <member name="M:Antlr3.Tool.GrammarAST.FindFirstType(System.Int32)">
            Return a reference to the first node (depth-first) that has
            token type ttype.  Assume 'this' is a root node; don't visit siblings
            of root.  Return null if no node found with ttype.
        </member>
        <member name="M:Antlr3.Tool.GrammarAST.HasSameTreeStructure(Antlr.Runtime.Tree.ITree)">
            See if tree has exact token types and structure; no text 
        </member>
        <member name="M:Antlr3.Tool.GrammarAST.DupTreeNoActions(Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST)">
            Duplicate a tree, assuming this is a root node of a tree--
            duplicate that node and what's below; ignore siblings of root node.
        </member>
        <member name="M:Antlr3.Tool.GrammarAST.SetTokenBoundaries(Antlr.Runtime.IToken,Antlr.Runtime.IToken)">
            Track start/stop token for subtree root created for a rule.
            Only works with Tree nodes.  For rules that match nothing,
            seems like this will yield start=i and stop=i-1 in a nil node.
            Might be useful info so I'll not force to be i..i.
        </member>
        <member name="M:Antlr3.Tool.GrammarAST.GetBlockAlt(System.Int32)">
            ** For every node in this subtree, make sure it's start/stop token's
        </member>
        <member name="T:Antlr3.Tool.GrammarAST.TreeTokenEqualityComparer">
            Make nodes unique based upon Token so we can add them to a Set; if
            not a GrammarAST, check type.
        </member>
        <member name="T:Antlr3.Tool.GrammarDanglingStateMessage">
            Reports a potential parsing issue with a decision; the decision is
            nondeterministic in some way.
        </member>
        <member name="T:Antlr3.Tool.GrammarNonDeterminismMessage">
            Reports a potential parsing issue with a decision; the decision is
            nondeterministic in some way.
        </member>
        <member name="F:Antlr3.Tool.GrammarReport.Version">
            Because I may change the stats, I need to track version for later
            computations to be consistent.
        </member>
        <member name="M:Antlr3.Tool.GrammarReport.ToNotifyString">
            Create a single-line stats report about this grammar suitable to
            send to the notify page at antlr.org
        </member>
        <member name="M:Antlr3.Tool.GrammarReport.ToString">
            Given a stats line suitable for sending to the antlr.org site,
            return a human-readable version.  Return null if there is a
            problem with the data.
        </member>
        <member name="T:Antlr3.Tool.GrammarReport2">
            Simplifying report dramatically for LL(*) paper.  Old results were
              wrong anyway it seems.  We need:
            
             		percent decisions that potentially backtrack
              	histogram of regular lookahead depth (int k or *)
        </member>
        <member name="T:Antlr3.Tool.GrammarSanity">
            Factor out routines that check sanity of rules, alts, grammars, etc.. 
        </member>
        <member name="F:Antlr3.Tool.GrammarSanity.visitedDuringRecursionCheck">
            The checkForLeftRecursion method needs to track what rules it has
            visited to track infinite recursion.
        </member>
        <member name="M:Antlr3.Tool.GrammarSanity.CheckAllRulesForLeftRecursion">
            Check all rules for infinite left recursion before analysis. Return list
            of troublesome rule cycles.  This method has two side-effects: it notifies
            the error manager that we have problems and it sets the list of
            recursive rules that we should ignore during analysis.
        </member>
        <member name="M:Antlr3.Tool.GrammarSanity.TraceStatesLookingForLeftRecursion(Antlr3.Analysis.NFAState,System.Collections.Generic.HashSet{System.Object},System.Collections.Generic.IList{System.Collections.Generic.HashSet{Antlr3.Tool.Rule}})">
            From state s, look for any transition to a rule that is currently
            being traced.  When tracing r, visitedDuringRecursionCheck has r
            initially.  If you reach an accept state, return but notify the
            invoking rule that it is nullable, which implies that invoking
            rule must look at follow transition for that invoking state.
            The visitedStates tracks visited states within a single rule so
            we can avoid epsilon-loop-induced infinite recursion here.  Keep
            filling the cycles in listOfRecursiveCycles and also, as a
            side-effect, set leftRecursiveRules.
        </member>
        <member name="M:Antlr3.Tool.GrammarSanity.AddRulesToCycle(Antlr3.Tool.Rule,Antlr3.Tool.Rule,System.Collections.Generic.IList{System.Collections.Generic.HashSet{Antlr3.Tool.Rule}})">
            enclosingRuleName calls targetRuleName, find the cycle containing
            the target and add the caller.  Find the cycle containing the caller
            and add the target.  If no cycles contain either, then create a new
            cycle.  listOfRecursiveCycles is List&lt;Set&lt;String&gt;&gt; that holds a list
            of cycles (sets of rule names).
        </member>
        <member name="M:Antlr3.Tool.GrammarSanity.EnsureAltIsSimpleNodeOrTree(Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST,System.Int32)">
            Rules in tree grammar that use -> rewrites and are spitting out
              templates via output=template and then use rewrite=true must only
              use -> on alts that are simple nodes or trees or single rule refs
              that match either nodes or trees.  The altAST is the ALT node
              for an ALT.  Verify that its first child is simple.  Must be either
              ( ALT ^( A B ) &lt;end-of-alt&gt; ) or ( ALT A &lt;end-of-alt&gt; ) or
              other element.
            
              Ignore predicates in front and labels.
        </member>
        <member name="T:Antlr3.Tool.GrammarSemanticsMessage">
            A problem with the symbols and/or meaning of a grammar such as rule
            redefinition.
        </member>
        <member name="F:Antlr3.Tool.GrammarSemanticsMessage.offendingToken">
            Most of the time, we'll have a token such as an undefined rule ref
            and so this will be set.
        </member>
        <member name="T:Antlr3.Tool.GrammarSpelunker">
            Load a grammar file and scan it just until we learn a few items
              of interest.  Currently: name, type, imports, tokenVocab, language option.
            
              GrammarScanner (at bottom of this class) converts grammar to stuff like:
            
               grammar Java ; options { backtrack true memoize true }
               import JavaDecl JavaAnnotations JavaExpr ;
               ... : ...
            
              First ':' or '@' indicates we can stop looking for imports/options.
            
              Then we just grab interesting grammar properties.
        </member>
        <member name="T:Antlr3.Tool.GrammarSpelunker.Scanner">
            Strip comments and then return stream of words and
            tokens {';', ':', '{', '}'}
        </member>
        <member name="M:Antlr3.Tool.GrammarSpelunker.Scanner.Id">
            NAME : LETTER+ ; // NAME is sequence of >=1 letter 
        </member>
        <member name="T:Antlr3.Tool.GrammarSyntaxMessage">
            A problem with the syntax of your antlr grammar such as
            "The '{' came as a complete surprise to me at this point in your program"
        </member>
        <member name="F:Antlr3.Tool.GrammarSyntaxMessage.offendingToken">
            Most of the time, we'll have a token and so this will be set. 
        </member>
        <member name="T:Antlr3.Tool.GrammarUnreachableAltsMessage">
            Reports a potential parsing issue with a decision; the decision is
            nondeterministic in some way.
        </member>
        <member name="T:Antlr3.Tool.IANTLRErrorListener">
            Defines behavior of object able to handle error messages from ANTLR including
            both tool errors like "can't write file" and grammar ambiguity warnings.
            To avoid having to change tools that use ANTLR (like GUIs), I am
            wrapping error data in Message objects and passing them to the listener.
            In this way, users of this interface are less sensitive to changes in
            the info I need for error messages.
        </member>
        <member name="T:Antlr3.Tool.Interpreter">
            The recognition interpreter/engine for grammars.  Separated
            out of Grammar as it's related, but technically not a Grammar function.
            You create an interpreter for a grammar and an input stream.  This object
            can act as a TokenSource so that you can hook up two grammars (via
            a CommonTokenStream) to lex/parse.  Being a token source only makes sense
            for a lexer grammar of course.
        </member>
        <member name="T:Antlr3.Tool.Interpreter.LexerActionGetTokenType">
            A lexer listener that just creates token objects as they
            are matched.  scan() use this listener to get a single object.
            To get a stream of tokens, you must call scan() multiple times,
            recording the token object result after each call.
        </member>
        <member name="M:Antlr3.Tool.Interpreter.Scan(System.String,Antlr.Runtime.Debug.IDebugEventListener,System.Collections.Generic.IList{Antlr3.Analysis.NFAState})">
            For a given input char stream, try to match against the NFA
              starting at startRule.  This is a deterministic parse even though
              it is using an NFA because it uses DFAs at each decision point to
              predict which alternative will succeed.  This is exactly what the
              generated parser will do.
            
              This only does lexer grammars.
            
              Return the token type associated with the final rule end state.
        </member>
        <member name="M:Antlr3.Tool.Interpreter.ParseEngine(System.String,Antlr3.Analysis.NFAState,Antlr3.Analysis.NFAState,Antlr.Runtime.IIntStream,System.Collections.Generic.Stack{System.Object},Antlr.Runtime.Debug.IDebugEventListener,System.Collections.Generic.IList{Antlr3.Analysis.NFAState})">
            Fill a list of all NFA states visited during the parse 
        </member>
        <member name="M:Antlr3.Tool.Interpreter.Predict(Antlr3.Analysis.DFA)">
            Given an input stream, return the unique alternative predicted by
            matching the input.  Upon error, return NFA.INVALID_ALT_NUMBER
            The first symbol of lookahead is presumed to be primed; that is,
            input.lookahead(1) must point at the input symbol you want to start
            predicting with.
        </member>
        <member name="T:Antlr3.Tool.LeftRecursionCyclesMessage">
            Similar to LeftRecursionMessage except this is used for announcing
            cycles found by walking rules without decisions; the other msg is
            invoked when a decision DFA construction finds a problem in closure.
        </member>
        <member name="M:Antlr3.Tool.LeftRecursiveRuleAnalyzer.TernaryAlt(Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST,System.Int32)">
            Convert e ? e : e  ->  ? e : e_[nextPrec] 
        </member>
        <member name="T:Antlr3.Tool.Message">
            The ANTLR code calls methods on ErrorManager to report errors etc...
              Rather than simply pass these arguments to the ANTLRErrorListener directly,
              create an object that encapsulates everything.  In this way, the error
              listener interface does not have to change when I add a new kind of
              error message.  I don't want to break a GUI for example every time
              I update the error system in ANTLR itself.
            
              To get a printable error/warning message, call toString().
        </member>
        <member name="M:Antlr3.Tool.Message.GetMessageTemplate">
            Return a new template instance every time someone tries to print
            a Message.
        </member>
        <member name="M:Antlr3.Tool.Message.GetLocationTemplate">
            Return a new template instance for the location part of a Message.
            TODO: Is this really necessary? -Kay
        </member>
        <member name="M:Antlr3.Tool.NameSpaceChecker.LookForReferencesToUndefinedSymbols">
            If ref to undefined rule, give error at first occurrence.
             
              Give error if you cannot find the scope override on a rule reference.
            
              If you ref ID in a combined grammar and don't define ID as a lexer rule
              it is an error.
        </member>
        <member name="M:Antlr3.Tool.NameSpaceChecker.CheckForRuleScopeAttributeConflict(Antlr3.Tool.Rule,Antlr3.Tool.Attribute)">
            Check for collision of a rule-scope dynamic attribute with:
            arg, return value, rule name itself.  Labels are checked elsewhere.
        </member>
        <member name="M:Antlr3.Tool.NameSpaceChecker.CheckForLabelConflict(Antlr3.Tool.Rule,Antlr.Runtime.IToken)">
            Make sure a label doesn't conflict with another symbol.
            Labels must not conflict with: rules, tokens, scope names,
            return values, parameters, and rule-scope dynamic attributes
            defined in surrounding rule.
        </member>
        <member name="M:Antlr3.Tool.NameSpaceChecker.CheckForLabelTypeMismatch(Antlr3.Tool.Rule,Antlr.Runtime.IToken,Antlr3.Tool.LabelType)">
            If type of previous label differs from new label's type, that's an error.
        </member>
        <member name="T:Antlr3.Tool.NFAFactory">
            Routines to construct StateClusters from EBNF grammar constructs.
              No optimization is done to remove unnecessary epsilon edges.
            
              TODO: add an optimization that reduces number of states and transitions
              will help with speed of conversion and make it easier to view NFA.  For
              example, o-A->o-->o-B->o should be o-A->o-B->o
        </member>
        <member name="F:Antlr3.Tool.NFAFactory._nfa">
            This factory is attached to a specifc NFA that it is building.
            The NFA will be filled up with states and transitions.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.OptimizeAlternative(Antlr3.Analysis.StateCluster)">
            Optimize an alternative (list of grammar elements).
            
              Walk the chain of elements (which can be complicated loop blocks...)
              and throw away any epsilon transitions used to link up simple elements.
            
              This only removes 195 states from the java.g's NFA, but every little
              bit helps.  Perhaps I can improve in the future.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAtom(System.Int32,Antlr3.Tool.GrammarAST)">
            From label A build Graph o-A->o 
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildSet(Antlr3.Misc.IIntSet,Antlr3.Tool.GrammarAST)">
            From set build single edge graph o->o-set->o.  To conform to
            what an alt block looks like, must have extra state on left.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildCharLiteralAtom(Antlr3.Tool.GrammarAST)">
            From char 'c' build StateCluster o-intValue(c)->o
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildCharRange(System.String,System.String)">
            From char 'c' build StateCluster o-intValue(c)->o
            can include unicode spec likes '\u0024' later.  Accepts
            actual unicode 16-bit now, of course, by default.
            TODO not supplemental char clean!
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildStringLiteralAtom(Antlr3.Tool.GrammarAST)">
            For a non-lexer, just build a simple token reference atom.
            For a lexer, a string is a sequence of char to match.  That is,
            "fog" is treated as 'f' 'o' 'g' not as a single transition in
            the DFA.  Machine== o-'f'->o-'o'->o-'g'->o and has n+1 states
            for n characters.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildRuleRef(Antlr3.Tool.Rule,Antlr3.Analysis.NFAState)">
            For reference to rule r, build
            
              o-e->(r)  o
            
              where (r) is the start of rule r and the trailing o is not linked
              to from rule ref state directly (it's done thru the transition(0)
              RuleClosureTransition.
            
              If the rule r is just a list of tokens, it's block will be just
              a set on an edge o->o->o-set->o->o->o, could inline it rather than doing
              the rule reference, but i'm not doing this yet as I'm not sure
              it would help much in the NFA->DFA construction.
            
              TODO add to codegen: collapse alt blks that are sets into single matchSet
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildEpsilon">
            From an empty alternative build StateCluster o-e->o 
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildSemanticPredicate(Antlr3.Tool.GrammarAST)">
            Build what amounts to an epsilon transition with a semantic
            predicate action.  The pred is a pointer into the AST of
            the SEMPRED token.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAction(Antlr3.Tool.GrammarAST)">
            Build what amounts to an epsilon transition with an action.
            The action goes into NFA though it is ignored during analysis.
            It slows things down a bit, but I must ignore predicates after
            having seen an action (5-5-2008).
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildEofStates(System.Collections.Generic.IEnumerable{Antlr3.Tool.Rule})">
            add an EOF transition to any rule end NFAState that points to nothing
              (i.e., for all those rules not invoked by another rule).  These
              are start symbols then.
            
              Return the number of grammar entry points; i.e., how many rules are
              not invoked by another rule (they can only be invoked from outside).
              These are the start rules.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildEofState(Antlr3.Analysis.NFAState)">
            set up an NFA NFAState that will yield eof tokens or,
            in the case of a lexer grammar, an EOT token when the conversion
            hits the end of a rule.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAB(Antlr3.Analysis.StateCluster,Antlr3.Analysis.StateCluster)">
            From A B build A-e->B (that is, build an epsilon arc from right
              of A to left of B).
            
              As a convenience, return B if A is null or return A if B is null.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAlternativeBlockFromSet(Antlr3.Analysis.StateCluster)">
            From a set ('a'|'b') build
            
              o->o-'a'..'b'->o->o (last NFAState is blockEndNFAState pointed to by all alts)
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAlternativeBlock(System.Collections.Generic.ICollection{Antlr3.Analysis.StateCluster})">
            From A|B|..|Z alternative block build
            
              o->o-A->o->o (last NFAState is blockEndNFAState pointed to by all alts)
              |          ^
              o->o-B->o--|
              |          |
              ...        |
              |          |
              o->o-Z->o--|
            
              So every alternative gets begin NFAState connected by epsilon
              and every alt right side points at a block end NFAState.  There is a
              new NFAState in the NFAState in the StateCluster for each alt plus one for the
              end NFAState.
            
              Special case: only one alternative: don't make a block with alt
              begin/end.
            
              Special case: if just a list of tokens/chars/sets, then collapse
              to a single edge'd o-set->o graph.
            
              Set alt number (1..n) in the left-Transition NFAState.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAoptional(Antlr3.Analysis.StateCluster)">
            From (A)? build either:
            
              o--A->o
              |     ^
              o---->|
            
              or, if A is a block, just add an empty alt to the end of the block
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAplus(Antlr3.Analysis.StateCluster)">
            From (A)+ build
            
                 |---|    (Transition 2 from A.right points at alt 1)
                 v   |    (follow of loop is Transition 1)
              o->o-A-o->o
            
              Meaning that the last NFAState in A points back to A's left Transition NFAState
              and we add a new begin/end NFAState.  A can be single alternative or
              multiple.
            
              During analysis we'll call the follow link (transition 1) alt n+1 for
              an n-alt A block.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildAstar(Antlr3.Analysis.StateCluster)">
            From (A)* build
            
                 |---|
                 v   |
              o->o-A-o--o (Transition 2 from block end points at alt 1; follow is Transition 1)
              |         ^
              o---------| (optional branch is 2nd alt of optional block containing A+)
            
              Meaning that the last (end) NFAState in A points back to A's
              left side NFAState and we add 3 new NFAStates (the
              optional branch is built just like an optional subrule).
              See the Aplus() method for more on the loop back Transition.
              The new node on right edge is set to RIGHT_EDGE_OF_CLOSURE so we
              can detect nested (A*)* loops and insert an extra node.  Previously,
              two blocks shared same EOB node.
            
              There are 2 or 3 decision points in a A*.  If A is not a block (i.e.,
              it only has one alt), then there are two decisions: the optional bypass
              and then loopback.  If A is a block of alts, then there are three
              decisions: bypass, loopback, and A's decision point.
            
              Note that the optional bypass must be outside the loop as (A|B)* is
              not the same thing as (A|B|)+.
            
              This is an accurate NFA representation of the meaning of (A)*, but
              for generating code, I don't need a DFA for the optional branch by
              virtue of how I generate code.  The exit-loopback-branch decision
              is sufficient to let me make an appropriate enter, exit, loop
              determination.  See codegen.g
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildWildcard(Antlr3.Tool.GrammarAST)">
            Build an atom with all possible values in its label 
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.BuildWildcardTree(Antlr3.Tool.GrammarAST)">
            Build a subrule matching ^(. .*) (any tree or node). Let's use
            (^(. .+) | .) to be safe.
        </member>
        <member name="M:Antlr3.Tool.NFAFactory.GetCollapsedBlockAsSet(Antlr3.Analysis.State)">
            Given a collapsed block of alts (a set of atoms), pull out
            the set and return it.
        </member>
        <member name="T:Antlr3.Tool.NonRegularDecisionMessage">
            More a single alternative recurses so this decision is not regular. 
        </member>
        <member name="T:Antlr3.Tool.RecursionOverflowMessage">
            Indicates recursion overflow.  A DFA state tried add an NFA configuration
            with NFA state p that was mentioned in its stack context too many times.
        </member>
        <member name="T:Antlr3.Tool.Rule">
            Combine the info associated with a rule. 
        </member>
        <member name="F:Antlr3.Tool.Rule._options">
            <summary>
            This rule's options.
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._tree">
            <summary>
            The AST representing the whole rule.
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._grammar">
            <summary>
            To which grammar does this belong?
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._argActionAST">
            <summary>
            For convenience, track the argument def AST action node if any.
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._returnScope">
            <summary>
            The return values of a rule and predefined rule attributes.
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._ruleScope">
            <summary>
            the attributes defined with "scope {...}" inside a rule
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._useScopes">
            <summary>
            A list of scope names used by this rule
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._throwsSpec">
            <summary>
            Exceptions that this rule can throw
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._tokenLabels">
            <summary>
            A list of all LabelElementPair attached to tokens like id=ID
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._wildcardTreeLabels">
            <summary>
            A list of all LabelElementPair attached to tokens like x=. in tree grammar
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._wildcardTreeListLabels">
            <summary>
            A list of all LabelElementPair attached to tokens like x+=. in tree grammar
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._charLabels">
            <summary>
            A list of all LabelElementPair attached to single char literals like x='a'
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._charListLabels">
            <summary>
            A list of all LabelElementPair attached to char literals like x+='a'
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._ruleLabels">
            <summary>
            A list of all LabelElementPair attached to rule references like f=field
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._tokenListLabels">
            <summary>
            A list of all Token list LabelElementPair like ids+=ID
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._ruleListLabels">
            <summary>
            A list of all rule ref list LabelElementPair like ids+=expr
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._labelNameSpace">
            <summary>
            All labels go in here (plus being split per the above lists) to
            catch dup label and label type mismatches.
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._actions">
            <summary>
            Map a name to an action for this rule.  Currently init is only
            one we use, but we can add more in future.
            The code generator will use this to fill holes in the rule template.
            I track the AST node for the action in case I need the line number
            for errors.  A better name is probably namedActions, but I don't
            want everyone to have to change their code gen templates now.
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._inlineActions">
            <summary>
            Track all executable actions other than named actions like @init.
            Also tracks exception handlers, predicates, and rewrite rewrites.
            We need to examine these actions before code generation so
            that we can detect refs to $rule.attr etc...
            </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._altToTokenRefMap">
             <summary>
             Each alt has a Map&lt;tokenRefName,List&lt;tokenRefAST&gt;&gt;; range 1..numberOfAlts.
             So, if there are 3 ID refs in a rule's alt number 2, you'll have
             altToTokenRef[2].get("ID").size()==3.  This is used to see if $ID is ok.
             There must be only one ID reference in the alt for $ID to be ok in
             an action--must be unique.
            
             This also tracks '+' and "int" literal token references
             (if not in LEXER).
            
             Rewrite rules force tracking of all tokens.
             </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._altToRuleRefMap">
             <summary>
             Each alt has a Map&lt;ruleRefName,List&lt;ruleRefAST&gt;&gt;; range 1..numberOfAlts
             So, if there are 3 expr refs in a rule's alt number 2, you'll have
             altToRuleRef[2].get("expr").size()==3.  This is used to see if $expr is ok.
             There must be only one expr reference in the alt for $expr to be ok in
             an action--must be unique.
            
             Rewrite rules force tracking of all rule result ASTs. 1..n
             </summary>
        </member>
        <member name="F:Antlr3.Tool.Rule._referencedPredefinedRuleAttributes">
            <summary>
            Do not generate start, stop etc... in a return value struct unless
            somebody references $r.start somewhere.
            </summary>
        </member>
        <member name="P:Antlr3.Tool.Rule.HasMultipleReturnValues">
            If a rule has no user-defined return values and nobody references
            it's start/stop (predefined attributes), then there is no need to
            define a struct; otherwise for now we assume a struct.  A rule also
            has multiple return values if you are building trees or templates.
        </member>
        <member name="M:Antlr3.Tool.Rule.TrackTokenReferenceInAlt(Antlr3.Tool.GrammarAST,System.Int32)">
            Track a token ID or literal like '+' and "void" as having been referenced
              somewhere within the alts (not rewrite sections) of a rule.
            
              This differs from Grammar.altReferencesTokenID(), which tracks all
              token IDs to check for token IDs without corresponding lexer rules.
        </member>
        <member name="M:Antlr3.Tool.Rule.GetAllTokenRefsInAltsWithRewrites">
            For use with rewrite rules, we must track all tokens matched on the
            left-hand-side; so we need Lists.  This is a unique list of all
            token types for which the rule needs a list of tokens.  This
            is called from the rule template not directly by the code generator.
        </member>
        <member name="M:Antlr3.Tool.Rule.GetAllRuleRefsInAltsWithRewrites">
            For use with rewrite rules, we must track all rule AST results on the
            left-hand-side; so we need Lists.  This is a unique list of all
            rule results for which the rule needs a list of results.
        </member>
        <member name="M:Antlr3.Tool.Rule.GetAttributeScope(System.String)">
            Return the scope containing name 
        </member>
        <member name="M:Antlr3.Tool.Rule.GetLocalAttributeScope(System.String)">
            Get the arg, return value, or predefined property for this rule 
        </member>
        <member name="M:Antlr3.Tool.Rule.GetElementLabel(System.String,System.Int32,Antlr3.Codegen.CodeGenerator)">
            For references to tokens rather than by label such as $ID, we
            need to get the existing label for the ID ref or create a new
            one.
        </member>
        <member name="M:Antlr3.Tool.Rule.DefineNamedAction(Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST,Antlr3.Tool.GrammarAST)">
            Given @scope::name {action} define it for this grammar.  Later,
            the code generator will ask for the actions table.
        </member>
        <member name="M:Antlr3.Tool.Rule.SetOption(System.String,System.Object,Antlr.Runtime.IToken)">
            Save the option key/value pair and process it; return the key
            or null if invalid option.
        </member>
        <member name="F:Antlr3.Tool.RuleLabelScope.predefinedRulePropertiesScope">
            Rules have a predefined set of attributes as well as
            the return values.  'text' needs to be computed though so.
        </member>
        <member name="M:Antlr3.Tool.RuleLabelScope.GetAttribute(System.String)">
            If you label a rule reference, you can access that rule's
            return values as well as any predefined attributes.
        </member>
        <member name="T:Antlr3.Tool.Strip">
            A basic action stripper. 
        </member>
        <member name="T:Antlr3.Tool.ToolMessage">
            A generic message from the tool such as "file not found" type errors; there
              is no reason to create a special object for each error unlike the grammar
              errors, which may be rather complex.
            
              Sometimes you need to pass in a filename or something to say it is "bad".
              Allow a generic object to be passed in and the string template can deal
              with just printing it or pulling a property out of it.
            
              TODO what to do with exceptions?  Want stack trace for internal errors?
        </member>
    </members>
</doc>
